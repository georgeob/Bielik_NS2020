{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "training_dataset = pd.read_csv('heart.csv')\ntrain_x = pd.read_csv('heart.csv')\ntrain_y = training_dataset[\"target\"]\ntrain_x\n\n\nX_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,test_size=0.20,random_state=0)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.shape",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "(242, 14)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y_test",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "225    0\n152    1\n228    0\n201    0\n52     1\n245    0\n175    0\n168    0\n223    0\n217    0\n111    1\n135    1\n218    0\n12     1\n15     1\n66     1\n97     1\n90     1\n198    0\n103    1\n22     1\n212    0\n226    0\n264    0\n133    1\n216    0\n275    0\n270    0\n154    1\n55     1\n      ..\n255    0\n134    1\n8      1\n157    1\n241    0\n240    0\n81     1\n214    0\n167    0\n5      1\n59     1\n92     1\n274    0\n34     1\n145    1\n116    1\n188    0\n246    0\n7      1\n45     1\n129    1\n122    1\n63     1\n124    1\n227    0\n146    1\n302    0\n26     1\n108    1\n89     1\nName: target, Length: 61, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(Dense(11,activation='relu',input_dim=14))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:tensorflow:From /home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "model.fit(X_train,Y_train,epochs=300)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/300\n242/242 [==============================] - 1s 2ms/step - loss: 13.4322 - accuracy: 0.4587\nEpoch 2/300\n242/242 [==============================] - 0s 105us/step - loss: 4.3187 - accuracy: 0.5041\nEpoch 3/300\n242/242 [==============================] - 0s 124us/step - loss: 4.2399 - accuracy: 0.6198\nEpoch 4/300\n242/242 [==============================] - 0s 140us/step - loss: 3.8454 - accuracy: 0.6033\nEpoch 5/300\n242/242 [==============================] - 0s 140us/step - loss: 2.7626 - accuracy: 0.5909\nEpoch 6/300\n242/242 [==============================] - 0s 125us/step - loss: 2.9458 - accuracy: 0.5496\nEpoch 7/300\n242/242 [==============================] - 0s 84us/step - loss: 2.5717 - accuracy: 0.5909\nEpoch 8/300\n242/242 [==============================] - 0s 90us/step - loss: 2.4697 - accuracy: 0.6322\nEpoch 9/300\n242/242 [==============================] - 0s 134us/step - loss: 2.3705 - accuracy: 0.6074\nEpoch 10/300\n242/242 [==============================] - 0s 116us/step - loss: 2.3166 - accuracy: 0.6074\nEpoch 11/300\n242/242 [==============================] - 0s 111us/step - loss: 2.2363 - accuracy: 0.6529\nEpoch 12/300\n242/242 [==============================] - 0s 98us/step - loss: 2.1730 - accuracy: 0.6529\nEpoch 13/300\n242/242 [==============================] - 0s 144us/step - loss: 2.1144 - accuracy: 0.6570\nEpoch 14/300\n242/242 [==============================] - 0s 133us/step - loss: 2.0745 - accuracy: 0.6529\nEpoch 15/300\n242/242 [==============================] - 0s 88us/step - loss: 2.1362 - accuracy: 0.6570\nEpoch 16/300\n242/242 [==============================] - 0s 52us/step - loss: 1.9596 - accuracy: 0.6736\nEpoch 17/300\n242/242 [==============================] - 0s 149us/step - loss: 1.9403 - accuracy: 0.6529\nEpoch 18/300\n242/242 [==============================] - 0s 111us/step - loss: 1.8854 - accuracy: 0.6653\nEpoch 19/300\n242/242 [==============================] - 0s 167us/step - loss: 1.8179 - accuracy: 0.6612\nEpoch 20/300\n242/242 [==============================] - 0s 115us/step - loss: 1.7825 - accuracy: 0.6529\nEpoch 21/300\n242/242 [==============================] - 0s 83us/step - loss: 1.7998 - accuracy: 0.6694\nEpoch 22/300\n242/242 [==============================] - 0s 90us/step - loss: 1.6558 - accuracy: 0.6860\nEpoch 23/300\n242/242 [==============================] - 0s 72us/step - loss: 1.6731 - accuracy: 0.6818\nEpoch 24/300\n242/242 [==============================] - 0s 63us/step - loss: 1.5966 - accuracy: 0.6653\nEpoch 25/300\n242/242 [==============================] - 0s 112us/step - loss: 1.5516 - accuracy: 0.6777\nEpoch 26/300\n242/242 [==============================] - 0s 118us/step - loss: 1.5184 - accuracy: 0.6860\nEpoch 27/300\n242/242 [==============================] - 0s 70us/step - loss: 1.4678 - accuracy: 0.6901\nEpoch 28/300\n242/242 [==============================] - 0s 93us/step - loss: 1.4121 - accuracy: 0.7066\nEpoch 29/300\n242/242 [==============================] - 0s 102us/step - loss: 1.3983 - accuracy: 0.7149\nEpoch 30/300\n242/242 [==============================] - 0s 74us/step - loss: 1.3225 - accuracy: 0.6942\nEpoch 31/300\n242/242 [==============================] - 0s 100us/step - loss: 1.3035 - accuracy: 0.7025\nEpoch 32/300\n242/242 [==============================] - 0s 101us/step - loss: 1.2404 - accuracy: 0.7190\nEpoch 33/300\n242/242 [==============================] - 0s 125us/step - loss: 1.2182 - accuracy: 0.6942\nEpoch 34/300\n242/242 [==============================] - 0s 103us/step - loss: 1.1517 - accuracy: 0.7066\nEpoch 35/300\n242/242 [==============================] - 0s 133us/step - loss: 1.1020 - accuracy: 0.7190\nEpoch 36/300\n242/242 [==============================] - 0s 61us/step - loss: 1.0885 - accuracy: 0.7107\nEpoch 37/300\n242/242 [==============================] - 0s 107us/step - loss: 1.0381 - accuracy: 0.7149\nEpoch 38/300\n242/242 [==============================] - 0s 77us/step - loss: 1.0041 - accuracy: 0.7314\nEpoch 39/300\n242/242 [==============================] - 0s 152us/step - loss: 0.9680 - accuracy: 0.7231\nEpoch 40/300\n242/242 [==============================] - 0s 123us/step - loss: 0.9514 - accuracy: 0.7066\nEpoch 41/300\n242/242 [==============================] - 0s 89us/step - loss: 0.9269 - accuracy: 0.7273\nEpoch 42/300\n242/242 [==============================] - 0s 134us/step - loss: 0.8646 - accuracy: 0.7355\nEpoch 43/300\n242/242 [==============================] - 0s 134us/step - loss: 0.8878 - accuracy: 0.7314\nEpoch 44/300\n242/242 [==============================] - 0s 76us/step - loss: 0.8225 - accuracy: 0.7562\nEpoch 45/300\n242/242 [==============================] - 0s 132us/step - loss: 0.8235 - accuracy: 0.7314\nEpoch 46/300\n242/242 [==============================] - 0s 100us/step - loss: 0.7228 - accuracy: 0.7562\nEpoch 47/300\n242/242 [==============================] - 0s 94us/step - loss: 0.7029 - accuracy: 0.7397\nEpoch 48/300\n242/242 [==============================] - 0s 137us/step - loss: 0.6858 - accuracy: 0.7438\nEpoch 49/300\n242/242 [==============================] - 0s 85us/step - loss: 0.6378 - accuracy: 0.7521\nEpoch 50/300\n242/242 [==============================] - 0s 77us/step - loss: 0.6420 - accuracy: 0.7645\nEpoch 51/300\n242/242 [==============================] - 0s 98us/step - loss: 0.6293 - accuracy: 0.7479\nEpoch 52/300\n242/242 [==============================] - 0s 88us/step - loss: 0.5915 - accuracy: 0.7727\nEpoch 53/300\n242/242 [==============================] - 0s 98us/step - loss: 0.5472 - accuracy: 0.7893\nEpoch 54/300\n242/242 [==============================] - 0s 122us/step - loss: 0.5248 - accuracy: 0.7975\nEpoch 55/300\n242/242 [==============================] - 0s 112us/step - loss: 0.5087 - accuracy: 0.8017\nEpoch 56/300\n242/242 [==============================] - 0s 95us/step - loss: 0.4987 - accuracy: 0.7975\nEpoch 57/300\n242/242 [==============================] - 0s 92us/step - loss: 0.4706 - accuracy: 0.8140\nEpoch 58/300\n242/242 [==============================] - 0s 166us/step - loss: 0.4870 - accuracy: 0.8140\nEpoch 59/300\n242/242 [==============================] - 0s 123us/step - loss: 0.4496 - accuracy: 0.8058\nEpoch 60/300\n242/242 [==============================] - 0s 146us/step - loss: 0.4266 - accuracy: 0.8306\nEpoch 61/300\n242/242 [==============================] - 0s 91us/step - loss: 0.4125 - accuracy: 0.8306\nEpoch 62/300\n242/242 [==============================] - 0s 150us/step - loss: 0.3938 - accuracy: 0.8430\nEpoch 63/300\n242/242 [==============================] - 0s 131us/step - loss: 0.3895 - accuracy: 0.8306\nEpoch 64/300\n242/242 [==============================] - 0s 115us/step - loss: 0.3892 - accuracy: 0.8347\nEpoch 65/300\n242/242 [==============================] - 0s 124us/step - loss: 0.3727 - accuracy: 0.8347\nEpoch 66/300\n242/242 [==============================] - 0s 112us/step - loss: 0.3619 - accuracy: 0.8554\nEpoch 67/300\n242/242 [==============================] - 0s 72us/step - loss: 0.3670 - accuracy: 0.8595\nEpoch 68/300\n242/242 [==============================] - 0s 90us/step - loss: 0.3765 - accuracy: 0.8306\nEpoch 69/300\n242/242 [==============================] - 0s 99us/step - loss: 0.3479 - accuracy: 0.8719\nEpoch 70/300\n242/242 [==============================] - 0s 83us/step - loss: 0.3256 - accuracy: 0.8554\nEpoch 71/300\n242/242 [==============================] - 0s 73us/step - loss: 0.3212 - accuracy: 0.8636\nEpoch 72/300\n242/242 [==============================] - 0s 106us/step - loss: 0.3201 - accuracy: 0.8388\nEpoch 73/300\n242/242 [==============================] - 0s 119us/step - loss: 0.3150 - accuracy: 0.8719\nEpoch 74/300\n242/242 [==============================] - 0s 130us/step - loss: 0.3236 - accuracy: 0.8347\nEpoch 75/300\n242/242 [==============================] - 0s 129us/step - loss: 0.3477 - accuracy: 0.8512\nEpoch 76/300\n242/242 [==============================] - 0s 87us/step - loss: 0.3359 - accuracy: 0.8595\nEpoch 77/300\n242/242 [==============================] - 0s 118us/step - loss: 0.3137 - accuracy: 0.8512\nEpoch 78/300\n242/242 [==============================] - 0s 86us/step - loss: 0.3036 - accuracy: 0.8512\nEpoch 79/300\n242/242 [==============================] - 0s 103us/step - loss: 0.2770 - accuracy: 0.8760\nEpoch 80/300\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "242/242 [==============================] - 0s 142us/step - loss: 0.2739 - accuracy: 0.8802\nEpoch 81/300\n242/242 [==============================] - 0s 108us/step - loss: 0.2737 - accuracy: 0.8719\nEpoch 82/300\n242/242 [==============================] - 0s 109us/step - loss: 0.2655 - accuracy: 0.8678\nEpoch 83/300\n242/242 [==============================] - 0s 118us/step - loss: 0.2898 - accuracy: 0.8760\nEpoch 84/300\n242/242 [==============================] - 0s 148us/step - loss: 0.2791 - accuracy: 0.8554\nEpoch 85/300\n242/242 [==============================] - 0s 77us/step - loss: 0.2609 - accuracy: 0.8760\nEpoch 86/300\n242/242 [==============================] - 0s 89us/step - loss: 0.2548 - accuracy: 0.8802\nEpoch 87/300\n242/242 [==============================] - 0s 137us/step - loss: 0.3153 - accuracy: 0.8636\nEpoch 88/300\n242/242 [==============================] - 0s 86us/step - loss: 0.2574 - accuracy: 0.8843\nEpoch 89/300\n242/242 [==============================] - 0s 181us/step - loss: 0.2549 - accuracy: 0.8926\nEpoch 90/300\n242/242 [==============================] - 0s 135us/step - loss: 0.3231 - accuracy: 0.8636\nEpoch 91/300\n242/242 [==============================] - 0s 84us/step - loss: 0.2558 - accuracy: 0.9050\nEpoch 92/300\n242/242 [==============================] - 0s 113us/step - loss: 0.2442 - accuracy: 0.8926\nEpoch 93/300\n242/242 [==============================] - 0s 73us/step - loss: 0.2865 - accuracy: 0.8884\nEpoch 94/300\n242/242 [==============================] - 0s 104us/step - loss: 0.2554 - accuracy: 0.8967\nEpoch 95/300\n242/242 [==============================] - 0s 90us/step - loss: 0.2667 - accuracy: 0.8802\nEpoch 96/300\n242/242 [==============================] - 0s 134us/step - loss: 0.2279 - accuracy: 0.9132\nEpoch 97/300\n242/242 [==============================] - 0s 121us/step - loss: 0.2263 - accuracy: 0.8967\nEpoch 98/300\n242/242 [==============================] - 0s 114us/step - loss: 0.2235 - accuracy: 0.8926\nEpoch 99/300\n242/242 [==============================] - 0s 155us/step - loss: 0.2200 - accuracy: 0.9091\nEpoch 100/300\n242/242 [==============================] - 0s 104us/step - loss: 0.2199 - accuracy: 0.8967\nEpoch 101/300\n242/242 [==============================] - 0s 173us/step - loss: 0.2191 - accuracy: 0.9008\nEpoch 102/300\n242/242 [==============================] - 0s 122us/step - loss: 0.2176 - accuracy: 0.9008\nEpoch 103/300\n242/242 [==============================] - 0s 142us/step - loss: 0.2163 - accuracy: 0.9008\nEpoch 104/300\n242/242 [==============================] - 0s 110us/step - loss: 0.2126 - accuracy: 0.9215\nEpoch 105/300\n242/242 [==============================] - 0s 106us/step - loss: 0.2042 - accuracy: 0.9091\nEpoch 106/300\n242/242 [==============================] - 0s 138us/step - loss: 0.2266 - accuracy: 0.9132\nEpoch 107/300\n242/242 [==============================] - 0s 128us/step - loss: 0.2270 - accuracy: 0.9132\nEpoch 108/300\n242/242 [==============================] - 0s 125us/step - loss: 0.2109 - accuracy: 0.9008\nEpoch 109/300\n242/242 [==============================] - 0s 198us/step - loss: 0.2004 - accuracy: 0.9215\nEpoch 110/300\n242/242 [==============================] - 0s 105us/step - loss: 0.1988 - accuracy: 0.9132\nEpoch 111/300\n242/242 [==============================] - 0s 128us/step - loss: 0.1952 - accuracy: 0.9215\nEpoch 112/300\n242/242 [==============================] - 0s 111us/step - loss: 0.1955 - accuracy: 0.9298\nEpoch 113/300\n242/242 [==============================] - 0s 138us/step - loss: 0.1929 - accuracy: 0.9215\nEpoch 114/300\n242/242 [==============================] - 0s 98us/step - loss: 0.1903 - accuracy: 0.9421\nEpoch 115/300\n242/242 [==============================] - 0s 154us/step - loss: 0.2108 - accuracy: 0.9132\nEpoch 116/300\n242/242 [==============================] - 0s 178us/step - loss: 0.1956 - accuracy: 0.9174\nEpoch 117/300\n242/242 [==============================] - 0s 83us/step - loss: 0.1957 - accuracy: 0.9215\nEpoch 118/300\n242/242 [==============================] - 0s 106us/step - loss: 0.1898 - accuracy: 0.9463\nEpoch 119/300\n242/242 [==============================] - 0s 95us/step - loss: 0.1811 - accuracy: 0.9298\nEpoch 120/300\n242/242 [==============================] - 0s 128us/step - loss: 0.1923 - accuracy: 0.9380\nEpoch 121/300\n242/242 [==============================] - 0s 78us/step - loss: 0.1968 - accuracy: 0.9091\nEpoch 122/300\n242/242 [==============================] - 0s 97us/step - loss: 0.2046 - accuracy: 0.9421\nEpoch 123/300\n242/242 [==============================] - 0s 131us/step - loss: 0.1728 - accuracy: 0.9298\nEpoch 124/300\n242/242 [==============================] - 0s 165us/step - loss: 0.1829 - accuracy: 0.9421\nEpoch 125/300\n242/242 [==============================] - 0s 109us/step - loss: 0.1742 - accuracy: 0.9339\nEpoch 126/300\n242/242 [==============================] - 0s 134us/step - loss: 0.1706 - accuracy: 0.9504\nEpoch 127/300\n242/242 [==============================] - 0s 73us/step - loss: 0.1748 - accuracy: 0.9380\nEpoch 128/300\n242/242 [==============================] - 0s 118us/step - loss: 0.1788 - accuracy: 0.9215\nEpoch 129/300\n242/242 [==============================] - 0s 130us/step - loss: 0.1761 - accuracy: 0.9421\nEpoch 130/300\n242/242 [==============================] - 0s 119us/step - loss: 0.1850 - accuracy: 0.9421\nEpoch 131/300\n242/242 [==============================] - 0s 84us/step - loss: 0.1692 - accuracy: 0.9421\nEpoch 132/300\n242/242 [==============================] - 0s 77us/step - loss: 0.1723 - accuracy: 0.9380\nEpoch 133/300\n242/242 [==============================] - 0s 124us/step - loss: 0.1721 - accuracy: 0.9174\nEpoch 134/300\n242/242 [==============================] - 0s 118us/step - loss: 0.1634 - accuracy: 0.9463\nEpoch 135/300\n242/242 [==============================] - 0s 75us/step - loss: 0.1595 - accuracy: 0.9421\nEpoch 136/300\n242/242 [==============================] - 0s 99us/step - loss: 0.1616 - accuracy: 0.9504\nEpoch 137/300\n242/242 [==============================] - 0s 151us/step - loss: 0.1552 - accuracy: 0.9421\nEpoch 138/300\n242/242 [==============================] - 0s 148us/step - loss: 0.1574 - accuracy: 0.9545\nEpoch 139/300\n242/242 [==============================] - 0s 142us/step - loss: 0.1614 - accuracy: 0.9421\nEpoch 140/300\n242/242 [==============================] - 0s 104us/step - loss: 0.1500 - accuracy: 0.9628\nEpoch 141/300\n242/242 [==============================] - 0s 128us/step - loss: 0.1506 - accuracy: 0.9421\nEpoch 142/300\n242/242 [==============================] - 0s 117us/step - loss: 0.1541 - accuracy: 0.9669\nEpoch 143/300\n242/242 [==============================] - 0s 251us/step - loss: 0.1615 - accuracy: 0.9463\nEpoch 144/300\n242/242 [==============================] - 0s 118us/step - loss: 0.1504 - accuracy: 0.9380\nEpoch 145/300\n242/242 [==============================] - 0s 139us/step - loss: 0.1566 - accuracy: 0.9504\nEpoch 146/300\n242/242 [==============================] - 0s 135us/step - loss: 0.1609 - accuracy: 0.9256\nEpoch 147/300\n242/242 [==============================] - 0s 164us/step - loss: 0.1775 - accuracy: 0.9256\nEpoch 148/300\n242/242 [==============================] - 0s 182us/step - loss: 0.1431 - accuracy: 0.9669\nEpoch 149/300\n242/242 [==============================] - 0s 195us/step - loss: 0.1503 - accuracy: 0.9339\nEpoch 150/300\n242/242 [==============================] - 0s 88us/step - loss: 0.1582 - accuracy: 0.9298\nEpoch 151/300\n242/242 [==============================] - 0s 71us/step - loss: 0.1438 - accuracy: 0.9752\nEpoch 152/300\n242/242 [==============================] - 0s 142us/step - loss: 0.1719 - accuracy: 0.9256\nEpoch 153/300\n242/242 [==============================] - 0s 121us/step - loss: 0.1553 - accuracy: 0.9463\nEpoch 154/300\n242/242 [==============================] - 0s 112us/step - loss: 0.1373 - accuracy: 0.9669\nEpoch 155/300\n242/242 [==============================] - 0s 139us/step - loss: 0.1344 - accuracy: 0.9587\nEpoch 156/300\n242/242 [==============================] - 0s 107us/step - loss: 0.1319 - accuracy: 0.9628\nEpoch 157/300\n242/242 [==============================] - 0s 211us/step - loss: 0.1331 - accuracy: 0.9752\nEpoch 158/300\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "242/242 [==============================] - 0s 230us/step - loss: 0.1377 - accuracy: 0.9711\nEpoch 159/300\n242/242 [==============================] - 0s 186us/step - loss: 0.1387 - accuracy: 0.9587\nEpoch 160/300\n242/242 [==============================] - 0s 136us/step - loss: 0.1567 - accuracy: 0.9298\nEpoch 161/300\n242/242 [==============================] - 0s 159us/step - loss: 0.1770 - accuracy: 0.9256\nEpoch 162/300\n242/242 [==============================] - 0s 189us/step - loss: 0.1570 - accuracy: 0.9628\nEpoch 163/300\n242/242 [==============================] - 0s 237us/step - loss: 0.1450 - accuracy: 0.9421\nEpoch 164/300\n242/242 [==============================] - 0s 140us/step - loss: 0.1259 - accuracy: 0.9669\nEpoch 165/300\n242/242 [==============================] - 0s 157us/step - loss: 0.1264 - accuracy: 0.9752\nEpoch 166/300\n242/242 [==============================] - 0s 147us/step - loss: 0.1225 - accuracy: 0.9752\nEpoch 167/300\n242/242 [==============================] - 0s 162us/step - loss: 0.1229 - accuracy: 0.9711\nEpoch 168/300\n242/242 [==============================] - 0s 143us/step - loss: 0.1371 - accuracy: 0.9669\nEpoch 169/300\n242/242 [==============================] - 0s 134us/step - loss: 0.1577 - accuracy: 0.9380\nEpoch 170/300\n242/242 [==============================] - 0s 174us/step - loss: 0.1519 - accuracy: 0.9298\nEpoch 171/300\n242/242 [==============================] - 0s 140us/step - loss: 0.1297 - accuracy: 0.9752\nEpoch 172/300\n242/242 [==============================] - 0s 158us/step - loss: 0.1169 - accuracy: 0.9669\nEpoch 173/300\n242/242 [==============================] - 0s 144us/step - loss: 0.1366 - accuracy: 0.9504\nEpoch 174/300\n242/242 [==============================] - 0s 178us/step - loss: 0.1156 - accuracy: 0.9752\nEpoch 175/300\n242/242 [==============================] - 0s 137us/step - loss: 0.1197 - accuracy: 0.9752\nEpoch 176/300\n242/242 [==============================] - 0s 114us/step - loss: 0.1150 - accuracy: 0.9752\nEpoch 177/300\n242/242 [==============================] - 0s 141us/step - loss: 0.1119 - accuracy: 0.9752\nEpoch 178/300\n242/242 [==============================] - 0s 99us/step - loss: 0.1164 - accuracy: 0.9669\nEpoch 179/300\n242/242 [==============================] - 0s 120us/step - loss: 0.1175 - accuracy: 0.9711\nEpoch 180/300\n242/242 [==============================] - 0s 162us/step - loss: 0.1144 - accuracy: 0.9669\nEpoch 181/300\n242/242 [==============================] - 0s 126us/step - loss: 0.1084 - accuracy: 0.9752\nEpoch 182/300\n242/242 [==============================] - 0s 166us/step - loss: 0.1178 - accuracy: 0.9711\nEpoch 183/300\n242/242 [==============================] - 0s 170us/step - loss: 0.1046 - accuracy: 0.9752\nEpoch 184/300\n242/242 [==============================] - 0s 174us/step - loss: 0.1100 - accuracy: 0.9711\nEpoch 185/300\n242/242 [==============================] - 0s 172us/step - loss: 0.1095 - accuracy: 0.9752\nEpoch 186/300\n242/242 [==============================] - 0s 66us/step - loss: 0.1068 - accuracy: 0.9752\nEpoch 187/300\n242/242 [==============================] - 0s 116us/step - loss: 0.1157 - accuracy: 0.9752\nEpoch 188/300\n242/242 [==============================] - 0s 153us/step - loss: 0.1071 - accuracy: 0.9669\nEpoch 189/300\n242/242 [==============================] - 0s 138us/step - loss: 0.1063 - accuracy: 0.9752\nEpoch 190/300\n242/242 [==============================] - 0s 148us/step - loss: 0.1052 - accuracy: 0.9793\nEpoch 191/300\n242/242 [==============================] - 0s 187us/step - loss: 0.1016 - accuracy: 0.9876\nEpoch 192/300\n242/242 [==============================] - 0s 145us/step - loss: 0.1054 - accuracy: 0.9752\nEpoch 193/300\n242/242 [==============================] - 0s 175us/step - loss: 0.1232 - accuracy: 0.9587\nEpoch 194/300\n242/242 [==============================] - 0s 160us/step - loss: 0.1059 - accuracy: 0.9752\nEpoch 195/300\n242/242 [==============================] - 0s 88us/step - loss: 0.1347 - accuracy: 0.9587\nEpoch 196/300\n242/242 [==============================] - 0s 163us/step - loss: 0.1129 - accuracy: 0.9669\nEpoch 197/300\n242/242 [==============================] - 0s 314us/step - loss: 0.1037 - accuracy: 0.9752\nEpoch 198/300\n242/242 [==============================] - 0s 148us/step - loss: 0.0967 - accuracy: 0.9793\nEpoch 199/300\n242/242 [==============================] - 0s 146us/step - loss: 0.1009 - accuracy: 0.9835\nEpoch 200/300\n242/242 [==============================] - 0s 189us/step - loss: 0.0972 - accuracy: 0.9835\nEpoch 201/300\n242/242 [==============================] - 0s 162us/step - loss: 0.1004 - accuracy: 0.9793\nEpoch 202/300\n242/242 [==============================] - 0s 113us/step - loss: 0.1007 - accuracy: 0.9835\nEpoch 203/300\n242/242 [==============================] - 0s 131us/step - loss: 0.1152 - accuracy: 0.9628\nEpoch 204/300\n242/242 [==============================] - 0s 125us/step - loss: 0.1542 - accuracy: 0.9339\nEpoch 205/300\n242/242 [==============================] - 0s 151us/step - loss: 0.1091 - accuracy: 0.9669\nEpoch 206/300\n242/242 [==============================] - 0s 114us/step - loss: 0.1041 - accuracy: 0.9793\nEpoch 207/300\n242/242 [==============================] - 0s 189us/step - loss: 0.0897 - accuracy: 0.9876\nEpoch 208/300\n242/242 [==============================] - 0s 129us/step - loss: 0.0973 - accuracy: 0.9835\nEpoch 209/300\n242/242 [==============================] - 0s 190us/step - loss: 0.1209 - accuracy: 0.9628\nEpoch 210/300\n242/242 [==============================] - 0s 127us/step - loss: 0.1014 - accuracy: 0.9793\nEpoch 211/300\n242/242 [==============================] - 0s 129us/step - loss: 0.0876 - accuracy: 0.9793\nEpoch 212/300\n242/242 [==============================] - 0s 90us/step - loss: 0.0894 - accuracy: 0.9835\nEpoch 213/300\n242/242 [==============================] - 0s 93us/step - loss: 0.0884 - accuracy: 0.9793\nEpoch 214/300\n242/242 [==============================] - 0s 78us/step - loss: 0.0895 - accuracy: 0.9835\nEpoch 215/300\n242/242 [==============================] - 0s 106us/step - loss: 0.0837 - accuracy: 0.9917\nEpoch 216/300\n242/242 [==============================] - 0s 129us/step - loss: 0.0837 - accuracy: 0.9917\nEpoch 217/300\n242/242 [==============================] - 0s 132us/step - loss: 0.0842 - accuracy: 0.9876\nEpoch 218/300\n242/242 [==============================] - 0s 128us/step - loss: 0.0830 - accuracy: 0.9917\nEpoch 219/300\n242/242 [==============================] - 0s 117us/step - loss: 0.0829 - accuracy: 0.9917\nEpoch 220/300\n242/242 [==============================] - 0s 127us/step - loss: 0.0861 - accuracy: 0.9752\nEpoch 221/300\n242/242 [==============================] - 0s 96us/step - loss: 0.0818 - accuracy: 0.9876\nEpoch 222/300\n242/242 [==============================] - 0s 157us/step - loss: 0.0802 - accuracy: 0.9959\nEpoch 223/300\n242/242 [==============================] - 0s 133us/step - loss: 0.0801 - accuracy: 0.9876\nEpoch 224/300\n242/242 [==============================] - 0s 151us/step - loss: 0.0848 - accuracy: 0.9917\nEpoch 225/300\n242/242 [==============================] - 0s 204us/step - loss: 0.0819 - accuracy: 0.9835\nEpoch 226/300\n242/242 [==============================] - 0s 206us/step - loss: 0.0851 - accuracy: 0.9752\nEpoch 227/300\n242/242 [==============================] - 0s 156us/step - loss: 0.0821 - accuracy: 0.9752\nEpoch 228/300\n242/242 [==============================] - 0s 177us/step - loss: 0.0762 - accuracy: 0.9917\nEpoch 229/300\n242/242 [==============================] - 0s 168us/step - loss: 0.0831 - accuracy: 0.9835\nEpoch 230/300\n242/242 [==============================] - 0s 130us/step - loss: 0.0884 - accuracy: 0.9835\nEpoch 231/300\n242/242 [==============================] - 0s 140us/step - loss: 0.0915 - accuracy: 0.9835\nEpoch 232/300\n242/242 [==============================] - 0s 109us/step - loss: 0.0718 - accuracy: 0.9959\nEpoch 233/300\n242/242 [==============================] - 0s 141us/step - loss: 0.0760 - accuracy: 0.9835\nEpoch 234/300\n242/242 [==============================] - 0s 124us/step - loss: 0.0724 - accuracy: 0.9959\nEpoch 235/300\n242/242 [==============================] - 0s 147us/step - loss: 0.0722 - accuracy: 0.9917\nEpoch 236/300\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "242/242 [==============================] - 0s 133us/step - loss: 0.0714 - accuracy: 0.9959\nEpoch 237/300\n242/242 [==============================] - 0s 165us/step - loss: 0.0728 - accuracy: 0.9959\nEpoch 238/300\n242/242 [==============================] - 0s 165us/step - loss: 0.0709 - accuracy: 0.9959\nEpoch 239/300\n242/242 [==============================] - 0s 115us/step - loss: 0.0688 - accuracy: 0.9959\nEpoch 240/300\n242/242 [==============================] - 0s 121us/step - loss: 0.0702 - accuracy: 0.9917\nEpoch 241/300\n242/242 [==============================] - 0s 140us/step - loss: 0.0726 - accuracy: 0.9835\nEpoch 242/300\n242/242 [==============================] - 0s 116us/step - loss: 0.0725 - accuracy: 0.9959\nEpoch 243/300\n242/242 [==============================] - 0s 178us/step - loss: 0.0765 - accuracy: 0.9876\nEpoch 244/300\n242/242 [==============================] - 0s 195us/step - loss: 0.0708 - accuracy: 0.9876\nEpoch 245/300\n242/242 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 1.00 - 0s 92us/step - loss: 0.0671 - accuracy: 0.9917\nEpoch 246/300\n242/242 [==============================] - 0s 96us/step - loss: 0.0672 - accuracy: 0.9959\nEpoch 247/300\n242/242 [==============================] - 0s 77us/step - loss: 0.0719 - accuracy: 0.9917\nEpoch 248/300\n242/242 [==============================] - 0s 94us/step - loss: 0.0748 - accuracy: 0.9835\nEpoch 249/300\n242/242 [==============================] - 0s 95us/step - loss: 0.0639 - accuracy: 0.9959\nEpoch 250/300\n242/242 [==============================] - 0s 73us/step - loss: 0.0651 - accuracy: 0.9959\nEpoch 251/300\n242/242 [==============================] - 0s 52us/step - loss: 0.0662 - accuracy: 0.9959\nEpoch 252/300\n242/242 [==============================] - 0s 88us/step - loss: 0.0669 - accuracy: 1.0000\nEpoch 253/300\n242/242 [==============================] - 0s 119us/step - loss: 0.0681 - accuracy: 0.9917\nEpoch 254/300\n242/242 [==============================] - 0s 158us/step - loss: 0.0753 - accuracy: 0.9959\nEpoch 255/300\n242/242 [==============================] - 0s 79us/step - loss: 0.0859 - accuracy: 0.9917\nEpoch 256/300\n242/242 [==============================] - 0s 143us/step - loss: 0.0615 - accuracy: 0.9959\nEpoch 257/300\n242/242 [==============================] - 0s 144us/step - loss: 0.0628 - accuracy: 0.9959\nEpoch 258/300\n242/242 [==============================] - 0s 138us/step - loss: 0.0631 - accuracy: 0.9959\nEpoch 259/300\n242/242 [==============================] - 0s 174us/step - loss: 0.0618 - accuracy: 0.9959\nEpoch 260/300\n242/242 [==============================] - 0s 104us/step - loss: 0.0611 - accuracy: 1.0000\nEpoch 261/300\n242/242 [==============================] - 0s 80us/step - loss: 0.0619 - accuracy: 0.9959\nEpoch 262/300\n242/242 [==============================] - 0s 116us/step - loss: 0.0660 - accuracy: 0.9917\nEpoch 263/300\n242/242 [==============================] - 0s 130us/step - loss: 0.0612 - accuracy: 1.0000\nEpoch 264/300\n242/242 [==============================] - 0s 100us/step - loss: 0.0621 - accuracy: 0.9959\nEpoch 265/300\n242/242 [==============================] - 0s 100us/step - loss: 0.0597 - accuracy: 0.9959\nEpoch 266/300\n242/242 [==============================] - 0s 103us/step - loss: 0.0614 - accuracy: 1.0000\nEpoch 267/300\n242/242 [==============================] - 0s 66us/step - loss: 0.0670 - accuracy: 0.9917\nEpoch 268/300\n242/242 [==============================] - 0s 137us/step - loss: 0.0595 - accuracy: 0.9959\nEpoch 269/300\n242/242 [==============================] - 0s 233us/step - loss: 0.0568 - accuracy: 0.9959\nEpoch 270/300\n242/242 [==============================] - 0s 228us/step - loss: 0.0560 - accuracy: 0.9959\nEpoch 271/300\n242/242 [==============================] - 0s 168us/step - loss: 0.0568 - accuracy: 0.9959\nEpoch 272/300\n242/242 [==============================] - 0s 87us/step - loss: 0.0583 - accuracy: 1.0000\nEpoch 273/300\n242/242 [==============================] - 0s 172us/step - loss: 0.0569 - accuracy: 1.0000\nEpoch 274/300\n242/242 [==============================] - 0s 95us/step - loss: 0.0567 - accuracy: 0.9959\nEpoch 275/300\n242/242 [==============================] - 0s 130us/step - loss: 0.0547 - accuracy: 0.9959\nEpoch 276/300\n242/242 [==============================] - 0s 115us/step - loss: 0.0540 - accuracy: 0.9959\nEpoch 277/300\n242/242 [==============================] - 0s 195us/step - loss: 0.0538 - accuracy: 1.0000\nEpoch 278/300\n242/242 [==============================] - 0s 142us/step - loss: 0.0533 - accuracy: 0.9959\nEpoch 279/300\n242/242 [==============================] - 0s 180us/step - loss: 0.0531 - accuracy: 1.0000\nEpoch 280/300\n242/242 [==============================] - 0s 133us/step - loss: 0.0550 - accuracy: 0.9959\nEpoch 281/300\n242/242 [==============================] - 0s 145us/step - loss: 0.0541 - accuracy: 1.0000\nEpoch 282/300\n242/242 [==============================] - 0s 109us/step - loss: 0.0565 - accuracy: 0.9959\nEpoch 283/300\n242/242 [==============================] - 0s 107us/step - loss: 0.0524 - accuracy: 0.9959\nEpoch 284/300\n242/242 [==============================] - 0s 150us/step - loss: 0.0520 - accuracy: 1.0000\nEpoch 285/300\n242/242 [==============================] - 0s 132us/step - loss: 0.0527 - accuracy: 1.0000\nEpoch 286/300\n242/242 [==============================] - 0s 135us/step - loss: 0.0508 - accuracy: 1.0000\nEpoch 287/300\n242/242 [==============================] - 0s 131us/step - loss: 0.0570 - accuracy: 0.9917\nEpoch 288/300\n242/242 [==============================] - 0s 91us/step - loss: 0.0619 - accuracy: 0.9835\nEpoch 289/300\n242/242 [==============================] - 0s 99us/step - loss: 0.0722 - accuracy: 0.9835\nEpoch 290/300\n242/242 [==============================] - 0s 195us/step - loss: 0.0535 - accuracy: 0.9959\nEpoch 291/300\n242/242 [==============================] - 0s 137us/step - loss: 0.0540 - accuracy: 0.9959\nEpoch 292/300\n242/242 [==============================] - 0s 248us/step - loss: 0.0501 - accuracy: 0.9959\nEpoch 293/300\n242/242 [==============================] - 0s 141us/step - loss: 0.0543 - accuracy: 1.0000\nEpoch 294/300\n242/242 [==============================] - 0s 142us/step - loss: 0.0473 - accuracy: 1.0000\nEpoch 295/300\n242/242 [==============================] - 0s 90us/step - loss: 0.0520 - accuracy: 1.0000\nEpoch 296/300\n242/242 [==============================] - 0s 195us/step - loss: 0.0493 - accuracy: 1.0000\nEpoch 297/300\n242/242 [==============================] - 0s 109us/step - loss: 0.0489 - accuracy: 0.9959\nEpoch 298/300\n242/242 [==============================] - 0s 110us/step - loss: 0.0474 - accuracy: 1.0000\nEpoch 299/300\n242/242 [==============================] - 0s 227us/step - loss: 0.0468 - accuracy: 1.0000\nEpoch 300/300\n242/242 [==============================] - 0s 186us/step - loss: 0.0499 - accuracy: 1.0000\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<keras.callbacks.callbacks.History at 0x7f5aa417a550>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "scores = model.evaluate(X_train, Y_train)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "242/242 [==============================] - 0s 461us/step\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\nPresnosť siete: %.2f%%\" % (scores[1]*100))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nPresnosť siete: 99.59%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_test.shape",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "(61, 14)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y_pred_nn = model.predict(X_test)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y_pred_nn.shape",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(61, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "rounded = [round(x[0]) for x in Y_pred_nn]\n\nY_pred_nn = rounded",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\nscore_nn = accuracy_score(Y_pred_nn,Y_test)*100,2\n\nprint(\"The accuracy score achieved using Neural Network is: \"+str(score_nn)+\" %\")",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "The accuracy score achieved using Neural Network is: (95.08196721311475, 2) %\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\n\nprint(\"Accuracy:\",metrics.accuracy_score(Y_pred_nn, Y_test))",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 0.9508196721311475\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\ndataset = pd.read_csv('heart.csv')\n# split into input (X) and output (Y) variables\nX = dataset.iloc[:,0:13].values\nY = dataset.iloc[:,13].values\n# create model\nmodel = Sequential()\nmodel.add(Dense(11, input_dim=13, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# Fit the model\nmodel.fit(X, Y, validation_split=0.20, epochs=500, batch_size=10)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 242 samples, validate on 61 samples\nEpoch 1/500\n242/242 [==============================] - 1s 2ms/step - loss: 5.5658 - accuracy: 0.6777 - val_loss: 8.6712 - val_accuracy: 0.0656\nEpoch 2/500\n242/242 [==============================] - 0s 268us/step - loss: 1.9466 - accuracy: 0.5372 - val_loss: 3.7146 - val_accuracy: 0.2295\nEpoch 3/500\n242/242 [==============================] - 0s 310us/step - loss: 1.5816 - accuracy: 0.5496 - val_loss: 3.6662 - val_accuracy: 0.1803\nEpoch 4/500\n242/242 [==============================] - 0s 487us/step - loss: 1.4105 - accuracy: 0.5868 - val_loss: 3.5787 - val_accuracy: 0.1475\nEpoch 5/500\n242/242 [==============================] - 0s 349us/step - loss: 1.3356 - accuracy: 0.5992 - val_loss: 3.0851 - val_accuracy: 0.1639\nEpoch 6/500\n242/242 [==============================] - 0s 283us/step - loss: 1.2537 - accuracy: 0.5702 - val_loss: 3.0636 - val_accuracy: 0.1475\nEpoch 7/500\n242/242 [==============================] - 0s 378us/step - loss: 1.1985 - accuracy: 0.5744 - val_loss: 2.9811 - val_accuracy: 0.1148\nEpoch 8/500\n242/242 [==============================] - 0s 376us/step - loss: 1.1381 - accuracy: 0.5785 - val_loss: 2.6611 - val_accuracy: 0.1475\nEpoch 9/500\n242/242 [==============================] - 0s 351us/step - loss: 1.0902 - accuracy: 0.5950 - val_loss: 2.7568 - val_accuracy: 0.0984\nEpoch 10/500\n242/242 [==============================] - 0s 342us/step - loss: 1.0303 - accuracy: 0.6116 - val_loss: 2.0553 - val_accuracy: 0.1967\nEpoch 11/500\n242/242 [==============================] - 0s 368us/step - loss: 1.0139 - accuracy: 0.5868 - val_loss: 2.1451 - val_accuracy: 0.1639\nEpoch 12/500\n242/242 [==============================] - 0s 329us/step - loss: 0.9480 - accuracy: 0.5950 - val_loss: 2.3095 - val_accuracy: 0.0984\nEpoch 13/500\n242/242 [==============================] - 0s 288us/step - loss: 0.9033 - accuracy: 0.5992 - val_loss: 1.9086 - val_accuracy: 0.1475\nEpoch 14/500\n242/242 [==============================] - 0s 295us/step - loss: 0.8652 - accuracy: 0.6033 - val_loss: 1.8732 - val_accuracy: 0.1311\nEpoch 15/500\n242/242 [==============================] - 0s 440us/step - loss: 0.8237 - accuracy: 0.6157 - val_loss: 2.0530 - val_accuracy: 0.0984\nEpoch 16/500\n242/242 [==============================] - 0s 233us/step - loss: 0.8061 - accuracy: 0.6198 - val_loss: 1.5268 - val_accuracy: 0.1475\nEpoch 17/500\n242/242 [==============================] - 0s 364us/step - loss: 0.7584 - accuracy: 0.6322 - val_loss: 1.5831 - val_accuracy: 0.1148\nEpoch 18/500\n242/242 [==============================] - 0s 625us/step - loss: 0.7352 - accuracy: 0.6322 - val_loss: 1.2842 - val_accuracy: 0.1639\nEpoch 19/500\n242/242 [==============================] - 0s 343us/step - loss: 0.7133 - accuracy: 0.6281 - val_loss: 1.1712 - val_accuracy: 0.1639\nEpoch 20/500\n242/242 [==============================] - 0s 332us/step - loss: 0.6783 - accuracy: 0.6488 - val_loss: 1.6132 - val_accuracy: 0.0820\nEpoch 21/500\n242/242 [==============================] - 0s 345us/step - loss: 0.6909 - accuracy: 0.6364 - val_loss: 1.3052 - val_accuracy: 0.1148\nEpoch 22/500\n242/242 [==============================] - 0s 314us/step - loss: 0.6435 - accuracy: 0.6612 - val_loss: 1.6156 - val_accuracy: 0.0492\nEpoch 23/500\n242/242 [==============================] - 0s 312us/step - loss: 0.6198 - accuracy: 0.6694 - val_loss: 1.3108 - val_accuracy: 0.0820\nEpoch 24/500\n242/242 [==============================] - 0s 384us/step - loss: 0.6192 - accuracy: 0.6818 - val_loss: 1.5267 - val_accuracy: 0.0492\nEpoch 25/500\n242/242 [==============================] - 0s 326us/step - loss: 0.5806 - accuracy: 0.6942 - val_loss: 0.8074 - val_accuracy: 0.5082\nEpoch 26/500\n242/242 [==============================] - 0s 249us/step - loss: 0.5979 - accuracy: 0.6901 - val_loss: 0.9719 - val_accuracy: 0.3770\nEpoch 27/500\n242/242 [==============================] - 0s 273us/step - loss: 0.5597 - accuracy: 0.7107 - val_loss: 1.2081 - val_accuracy: 0.1148\nEpoch 28/500\n242/242 [==============================] - 0s 299us/step - loss: 0.5637 - accuracy: 0.6901 - val_loss: 0.8775 - val_accuracy: 0.4754\nEpoch 29/500\n242/242 [==============================] - 0s 286us/step - loss: 0.5749 - accuracy: 0.6901 - val_loss: 0.6062 - val_accuracy: 0.6885\nEpoch 30/500\n242/242 [==============================] - 0s 281us/step - loss: 0.5736 - accuracy: 0.6694 - val_loss: 0.6894 - val_accuracy: 0.6230\nEpoch 31/500\n242/242 [==============================] - 0s 284us/step - loss: 0.5456 - accuracy: 0.7066 - val_loss: 0.9894 - val_accuracy: 0.3607\nEpoch 32/500\n242/242 [==============================] - 0s 352us/step - loss: 0.5349 - accuracy: 0.7149 - val_loss: 0.8865 - val_accuracy: 0.5082\nEpoch 33/500\n242/242 [==============================] - 0s 242us/step - loss: 0.5218 - accuracy: 0.7273 - val_loss: 1.2301 - val_accuracy: 0.2623\nEpoch 34/500\n242/242 [==============================] - 0s 349us/step - loss: 0.5310 - accuracy: 0.7149 - val_loss: 1.2526 - val_accuracy: 0.2295\nEpoch 35/500\n242/242 [==============================] - 0s 285us/step - loss: 0.5191 - accuracy: 0.7355 - val_loss: 0.6828 - val_accuracy: 0.6393\nEpoch 36/500\n242/242 [==============================] - 0s 292us/step - loss: 0.5096 - accuracy: 0.7603 - val_loss: 1.0422 - val_accuracy: 0.3443\nEpoch 37/500\n242/242 [==============================] - 0s 229us/step - loss: 0.5119 - accuracy: 0.7190 - val_loss: 0.8804 - val_accuracy: 0.5082\nEpoch 38/500\n242/242 [==============================] - 0s 312us/step - loss: 0.5110 - accuracy: 0.7355 - val_loss: 0.7433 - val_accuracy: 0.5738\nEpoch 39/500\n242/242 [==============================] - 0s 346us/step - loss: 0.5038 - accuracy: 0.7438 - val_loss: 0.6607 - val_accuracy: 0.6721\nEpoch 40/500\n242/242 [==============================] - 0s 244us/step - loss: 0.5202 - accuracy: 0.7314 - val_loss: 1.4278 - val_accuracy: 0.2295\nEpoch 41/500\n242/242 [==============================] - 0s 265us/step - loss: 0.4946 - accuracy: 0.7397 - val_loss: 0.9870 - val_accuracy: 0.3934\nEpoch 42/500\n242/242 [==============================] - 0s 360us/step - loss: 0.5038 - accuracy: 0.7521 - val_loss: 0.9207 - val_accuracy: 0.4754\nEpoch 43/500\n242/242 [==============================] - 0s 518us/step - loss: 0.4862 - accuracy: 0.7521 - val_loss: 1.0405 - val_accuracy: 0.3934\nEpoch 44/500\n242/242 [==============================] - 0s 556us/step - loss: 0.5076 - accuracy: 0.7562 - val_loss: 1.0967 - val_accuracy: 0.3607\nEpoch 45/500\n242/242 [==============================] - 0s 350us/step - loss: 0.4768 - accuracy: 0.7810 - val_loss: 0.7476 - val_accuracy: 0.6066\nEpoch 46/500\n242/242 [==============================] - 0s 467us/step - loss: 0.4824 - accuracy: 0.7562 - val_loss: 0.8176 - val_accuracy: 0.5082\nEpoch 47/500\n242/242 [==============================] - 0s 354us/step - loss: 0.4790 - accuracy: 0.7562 - val_loss: 1.0074 - val_accuracy: 0.4262\nEpoch 48/500\n242/242 [==============================] - 0s 373us/step - loss: 0.4830 - accuracy: 0.7603 - val_loss: 0.7589 - val_accuracy: 0.5902\nEpoch 49/500\n242/242 [==============================] - 0s 455us/step - loss: 0.4792 - accuracy: 0.7893 - val_loss: 0.6882 - val_accuracy: 0.6393\nEpoch 50/500\n242/242 [==============================] - 0s 467us/step - loss: 0.4663 - accuracy: 0.7893 - val_loss: 1.0345 - val_accuracy: 0.3934\nEpoch 51/500\n242/242 [==============================] - 0s 491us/step - loss: 0.4723 - accuracy: 0.7769 - val_loss: 1.0698 - val_accuracy: 0.3934\nEpoch 52/500\n242/242 [==============================] - 0s 432us/step - loss: 0.4673 - accuracy: 0.7603 - val_loss: 0.9935 - val_accuracy: 0.4262\nEpoch 53/500\n242/242 [==============================] - 0s 457us/step - loss: 0.4585 - accuracy: 0.7769 - val_loss: 1.1140 - val_accuracy: 0.3934\nEpoch 54/500\n242/242 [==============================] - 0s 429us/step - loss: 0.4736 - accuracy: 0.7810 - val_loss: 1.0350 - val_accuracy: 0.4262\nEpoch 55/500\n242/242 [==============================] - 0s 557us/step - loss: 0.4613 - accuracy: 0.7851 - val_loss: 0.8905 - val_accuracy: 0.4754\nEpoch 56/500\n242/242 [==============================] - 0s 433us/step - loss: 0.4510 - accuracy: 0.8017 - val_loss: 0.7169 - val_accuracy: 0.6230\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 57/500\n242/242 [==============================] - 0s 399us/step - loss: 0.4824 - accuracy: 0.7562 - val_loss: 1.0961 - val_accuracy: 0.3770\nEpoch 58/500\n242/242 [==============================] - 0s 376us/step - loss: 0.4761 - accuracy: 0.7686 - val_loss: 1.2076 - val_accuracy: 0.3115\nEpoch 59/500\n242/242 [==============================] - 0s 356us/step - loss: 0.4638 - accuracy: 0.8017 - val_loss: 1.0649 - val_accuracy: 0.3934\nEpoch 60/500\n242/242 [==============================] - 0s 322us/step - loss: 0.4494 - accuracy: 0.7851 - val_loss: 0.8962 - val_accuracy: 0.4918\nEpoch 61/500\n242/242 [==============================] - 0s 353us/step - loss: 0.4630 - accuracy: 0.7851 - val_loss: 0.9986 - val_accuracy: 0.4590\nEpoch 62/500\n242/242 [==============================] - 0s 462us/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.9242 - val_accuracy: 0.4918\nEpoch 63/500\n242/242 [==============================] - 0s 425us/step - loss: 0.4410 - accuracy: 0.7851 - val_loss: 0.8470 - val_accuracy: 0.5902\nEpoch 64/500\n242/242 [==============================] - 0s 408us/step - loss: 0.4422 - accuracy: 0.7769 - val_loss: 1.0825 - val_accuracy: 0.4098\nEpoch 65/500\n242/242 [==============================] - 0s 527us/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.7027 - val_accuracy: 0.6557\nEpoch 66/500\n242/242 [==============================] - 0s 341us/step - loss: 0.4467 - accuracy: 0.7851 - val_loss: 0.9762 - val_accuracy: 0.4918\nEpoch 67/500\n242/242 [==============================] - 0s 449us/step - loss: 0.4343 - accuracy: 0.7810 - val_loss: 1.0291 - val_accuracy: 0.4426\nEpoch 68/500\n242/242 [==============================] - 0s 517us/step - loss: 0.4304 - accuracy: 0.8017 - val_loss: 0.8476 - val_accuracy: 0.5246\nEpoch 69/500\n242/242 [==============================] - 0s 459us/step - loss: 0.4566 - accuracy: 0.7686 - val_loss: 0.5285 - val_accuracy: 0.7541\nEpoch 70/500\n242/242 [==============================] - 0s 442us/step - loss: 0.4579 - accuracy: 0.7769 - val_loss: 0.7698 - val_accuracy: 0.5902\nEpoch 71/500\n242/242 [==============================] - 0s 515us/step - loss: 0.4189 - accuracy: 0.8223 - val_loss: 0.6791 - val_accuracy: 0.6557\nEpoch 72/500\n242/242 [==============================] - 0s 397us/step - loss: 0.4252 - accuracy: 0.8264 - val_loss: 0.7822 - val_accuracy: 0.6066\nEpoch 73/500\n242/242 [==============================] - 0s 425us/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.8163 - val_accuracy: 0.5738\nEpoch 74/500\n242/242 [==============================] - 0s 492us/step - loss: 0.4275 - accuracy: 0.7934 - val_loss: 1.0626 - val_accuracy: 0.3607\nEpoch 75/500\n242/242 [==============================] - 0s 394us/step - loss: 0.4255 - accuracy: 0.8017 - val_loss: 1.1171 - val_accuracy: 0.3607\nEpoch 76/500\n242/242 [==============================] - 0s 379us/step - loss: 0.4139 - accuracy: 0.8140 - val_loss: 0.5889 - val_accuracy: 0.7049\nEpoch 77/500\n242/242 [==============================] - 0s 503us/step - loss: 0.4215 - accuracy: 0.8017 - val_loss: 0.7818 - val_accuracy: 0.6066\nEpoch 78/500\n242/242 [==============================] - 0s 559us/step - loss: 0.4052 - accuracy: 0.8182 - val_loss: 1.0793 - val_accuracy: 0.3279\nEpoch 79/500\n242/242 [==============================] - 0s 492us/step - loss: 0.4163 - accuracy: 0.8058 - val_loss: 0.8810 - val_accuracy: 0.5738\nEpoch 80/500\n242/242 [==============================] - 0s 483us/step - loss: 0.4071 - accuracy: 0.8223 - val_loss: 0.5901 - val_accuracy: 0.6885\nEpoch 81/500\n242/242 [==============================] - 0s 311us/step - loss: 0.4159 - accuracy: 0.8140 - val_loss: 0.9283 - val_accuracy: 0.4918\nEpoch 82/500\n242/242 [==============================] - 0s 362us/step - loss: 0.4131 - accuracy: 0.8182 - val_loss: 0.8103 - val_accuracy: 0.5574\nEpoch 83/500\n242/242 [==============================] - 0s 334us/step - loss: 0.3956 - accuracy: 0.8223 - val_loss: 0.8279 - val_accuracy: 0.5574\nEpoch 84/500\n242/242 [==============================] - 0s 432us/step - loss: 0.3978 - accuracy: 0.8347 - val_loss: 0.6920 - val_accuracy: 0.6066\nEpoch 85/500\n242/242 [==============================] - 0s 266us/step - loss: 0.3906 - accuracy: 0.8347 - val_loss: 0.9018 - val_accuracy: 0.5410\nEpoch 86/500\n242/242 [==============================] - 0s 354us/step - loss: 0.3896 - accuracy: 0.8347 - val_loss: 0.9124 - val_accuracy: 0.4754\nEpoch 87/500\n242/242 [==============================] - 0s 353us/step - loss: 0.3838 - accuracy: 0.8430 - val_loss: 0.8611 - val_accuracy: 0.5246\nEpoch 88/500\n242/242 [==============================] - 0s 306us/step - loss: 0.3951 - accuracy: 0.8471 - val_loss: 0.9360 - val_accuracy: 0.5246\nEpoch 89/500\n242/242 [==============================] - 0s 387us/step - loss: 0.3743 - accuracy: 0.8471 - val_loss: 0.9390 - val_accuracy: 0.4754\nEpoch 90/500\n242/242 [==============================] - 0s 310us/step - loss: 0.3785 - accuracy: 0.8512 - val_loss: 0.7714 - val_accuracy: 0.5574\nEpoch 91/500\n242/242 [==============================] - 0s 440us/step - loss: 0.3744 - accuracy: 0.8347 - val_loss: 1.0954 - val_accuracy: 0.4098\nEpoch 92/500\n242/242 [==============================] - 0s 388us/step - loss: 0.4050 - accuracy: 0.8017 - val_loss: 1.0980 - val_accuracy: 0.4262\nEpoch 93/500\n242/242 [==============================] - 0s 391us/step - loss: 0.4185 - accuracy: 0.8058 - val_loss: 0.6652 - val_accuracy: 0.6393\nEpoch 94/500\n242/242 [==============================] - 0s 471us/step - loss: 0.3703 - accuracy: 0.8471 - val_loss: 0.8812 - val_accuracy: 0.5246\nEpoch 95/500\n242/242 [==============================] - 0s 389us/step - loss: 0.3803 - accuracy: 0.8388 - val_loss: 0.6518 - val_accuracy: 0.6066\nEpoch 96/500\n242/242 [==============================] - 0s 520us/step - loss: 0.3707 - accuracy: 0.8347 - val_loss: 0.8289 - val_accuracy: 0.5574\nEpoch 97/500\n242/242 [==============================] - 0s 348us/step - loss: 0.3665 - accuracy: 0.8512 - val_loss: 0.8151 - val_accuracy: 0.5410\nEpoch 98/500\n242/242 [==============================] - 0s 361us/step - loss: 0.3793 - accuracy: 0.8306 - val_loss: 0.4980 - val_accuracy: 0.7377\nEpoch 99/500\n242/242 [==============================] - 0s 499us/step - loss: 0.3626 - accuracy: 0.8388 - val_loss: 0.5566 - val_accuracy: 0.6885\nEpoch 100/500\n242/242 [==============================] - 0s 352us/step - loss: 0.3770 - accuracy: 0.8347 - val_loss: 1.0328 - val_accuracy: 0.4590\nEpoch 101/500\n242/242 [==============================] - 0s 416us/step - loss: 0.3946 - accuracy: 0.8388 - val_loss: 0.8604 - val_accuracy: 0.5246\nEpoch 102/500\n242/242 [==============================] - 0s 656us/step - loss: 0.3664 - accuracy: 0.8430 - val_loss: 0.7091 - val_accuracy: 0.5902\nEpoch 103/500\n242/242 [==============================] - 0s 513us/step - loss: 0.3839 - accuracy: 0.8306 - val_loss: 0.4909 - val_accuracy: 0.7541\nEpoch 104/500\n242/242 [==============================] - 0s 439us/step - loss: 0.3658 - accuracy: 0.8471 - val_loss: 0.9006 - val_accuracy: 0.5246\nEpoch 105/500\n242/242 [==============================] - 0s 364us/step - loss: 0.3569 - accuracy: 0.8471 - val_loss: 0.7211 - val_accuracy: 0.5738\nEpoch 106/500\n242/242 [==============================] - 0s 413us/step - loss: 0.3563 - accuracy: 0.8512 - val_loss: 0.6221 - val_accuracy: 0.6230\nEpoch 107/500\n242/242 [==============================] - 0s 409us/step - loss: 0.3526 - accuracy: 0.8636 - val_loss: 0.8643 - val_accuracy: 0.5246\nEpoch 108/500\n242/242 [==============================] - 0s 320us/step - loss: 0.3525 - accuracy: 0.8388 - val_loss: 0.8133 - val_accuracy: 0.5410\nEpoch 109/500\n242/242 [==============================] - 0s 374us/step - loss: 0.3576 - accuracy: 0.8430 - val_loss: 0.7767 - val_accuracy: 0.5574\nEpoch 110/500\n242/242 [==============================] - 0s 463us/step - loss: 0.3608 - accuracy: 0.8388 - val_loss: 0.6828 - val_accuracy: 0.6066\nEpoch 111/500\n242/242 [==============================] - 0s 338us/step - loss: 0.3503 - accuracy: 0.8471 - val_loss: 0.6132 - val_accuracy: 0.6393\nEpoch 112/500\n242/242 [==============================] - 0s 338us/step - loss: 0.3641 - accuracy: 0.8388 - val_loss: 0.8526 - val_accuracy: 0.5410\nEpoch 113/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "242/242 [==============================] - 0s 404us/step - loss: 0.3504 - accuracy: 0.8678 - val_loss: 1.0143 - val_accuracy: 0.5082\nEpoch 114/500\n242/242 [==============================] - 0s 314us/step - loss: 0.3595 - accuracy: 0.8471 - val_loss: 0.4507 - val_accuracy: 0.7541\nEpoch 115/500\n242/242 [==============================] - 0s 387us/step - loss: 0.3621 - accuracy: 0.8306 - val_loss: 0.8406 - val_accuracy: 0.5246\nEpoch 116/500\n242/242 [==============================] - 0s 347us/step - loss: 0.3523 - accuracy: 0.8554 - val_loss: 0.6275 - val_accuracy: 0.6557\nEpoch 117/500\n242/242 [==============================] - 0s 448us/step - loss: 0.3596 - accuracy: 0.8595 - val_loss: 0.5473 - val_accuracy: 0.7049\nEpoch 118/500\n242/242 [==============================] - 0s 335us/step - loss: 0.3667 - accuracy: 0.8471 - val_loss: 0.4069 - val_accuracy: 0.7869\nEpoch 119/500\n242/242 [==============================] - 0s 278us/step - loss: 0.3710 - accuracy: 0.8636 - val_loss: 0.6183 - val_accuracy: 0.6393\nEpoch 120/500\n242/242 [==============================] - 0s 459us/step - loss: 0.3460 - accuracy: 0.8554 - val_loss: 0.6130 - val_accuracy: 0.6721\nEpoch 121/500\n242/242 [==============================] - 0s 516us/step - loss: 0.3446 - accuracy: 0.8554 - val_loss: 0.8617 - val_accuracy: 0.5410\nEpoch 122/500\n242/242 [==============================] - 0s 431us/step - loss: 0.3452 - accuracy: 0.8430 - val_loss: 0.6505 - val_accuracy: 0.6557\nEpoch 123/500\n242/242 [==============================] - 0s 399us/step - loss: 0.3605 - accuracy: 0.8471 - val_loss: 0.6679 - val_accuracy: 0.6066\nEpoch 124/500\n242/242 [==============================] - 0s 421us/step - loss: 0.3514 - accuracy: 0.8471 - val_loss: 1.0328 - val_accuracy: 0.5082\nEpoch 125/500\n242/242 [==============================] - 0s 409us/step - loss: 0.3741 - accuracy: 0.8430 - val_loss: 1.6300 - val_accuracy: 0.3279\nEpoch 126/500\n242/242 [==============================] - 0s 399us/step - loss: 0.3788 - accuracy: 0.8347 - val_loss: 0.8425 - val_accuracy: 0.5574\nEpoch 127/500\n242/242 [==============================] - 0s 529us/step - loss: 0.3575 - accuracy: 0.8430 - val_loss: 0.9881 - val_accuracy: 0.5082\nEpoch 128/500\n242/242 [==============================] - 0s 488us/step - loss: 0.3478 - accuracy: 0.8554 - val_loss: 0.8364 - val_accuracy: 0.5574\nEpoch 129/500\n242/242 [==============================] - 0s 433us/step - loss: 0.3382 - accuracy: 0.8595 - val_loss: 0.6629 - val_accuracy: 0.6393\nEpoch 130/500\n242/242 [==============================] - 0s 434us/step - loss: 0.3427 - accuracy: 0.8554 - val_loss: 1.4186 - val_accuracy: 0.3443\nEpoch 131/500\n242/242 [==============================] - 0s 491us/step - loss: 0.3900 - accuracy: 0.8140 - val_loss: 1.0187 - val_accuracy: 0.5082\nEpoch 132/500\n242/242 [==============================] - 0s 392us/step - loss: 0.3412 - accuracy: 0.8471 - val_loss: 0.6317 - val_accuracy: 0.6557\nEpoch 133/500\n242/242 [==============================] - 0s 574us/step - loss: 0.3437 - accuracy: 0.8843 - val_loss: 0.4740 - val_accuracy: 0.7541\nEpoch 134/500\n242/242 [==============================] - 0s 460us/step - loss: 0.3668 - accuracy: 0.8554 - val_loss: 0.4708 - val_accuracy: 0.7541\nEpoch 135/500\n242/242 [==============================] - 0s 448us/step - loss: 0.3298 - accuracy: 0.8554 - val_loss: 0.9562 - val_accuracy: 0.5410\nEpoch 136/500\n242/242 [==============================] - 0s 442us/step - loss: 0.3341 - accuracy: 0.8595 - val_loss: 0.5520 - val_accuracy: 0.6885\nEpoch 137/500\n242/242 [==============================] - 0s 390us/step - loss: 0.3694 - accuracy: 0.8512 - val_loss: 0.6470 - val_accuracy: 0.6557\nEpoch 138/500\n242/242 [==============================] - 0s 416us/step - loss: 0.3382 - accuracy: 0.8636 - val_loss: 0.7093 - val_accuracy: 0.5902\nEpoch 139/500\n242/242 [==============================] - 0s 251us/step - loss: 0.3381 - accuracy: 0.8636 - val_loss: 0.6705 - val_accuracy: 0.6230\nEpoch 140/500\n242/242 [==============================] - 0s 393us/step - loss: 0.3418 - accuracy: 0.8554 - val_loss: 0.7542 - val_accuracy: 0.5574\nEpoch 141/500\n242/242 [==============================] - 0s 376us/step - loss: 0.3331 - accuracy: 0.8595 - val_loss: 0.8985 - val_accuracy: 0.5410\nEpoch 142/500\n242/242 [==============================] - 0s 485us/step - loss: 0.3474 - accuracy: 0.8347 - val_loss: 0.8565 - val_accuracy: 0.5574\nEpoch 143/500\n242/242 [==============================] - 0s 444us/step - loss: 0.3398 - accuracy: 0.8554 - val_loss: 0.8610 - val_accuracy: 0.5574\nEpoch 144/500\n242/242 [==============================] - 0s 345us/step - loss: 0.3278 - accuracy: 0.8554 - val_loss: 0.7994 - val_accuracy: 0.5574\nEpoch 145/500\n242/242 [==============================] - 0s 440us/step - loss: 0.3258 - accuracy: 0.8636 - val_loss: 0.8932 - val_accuracy: 0.5574\nEpoch 146/500\n242/242 [==============================] - 0s 405us/step - loss: 0.3365 - accuracy: 0.8554 - val_loss: 0.6646 - val_accuracy: 0.6393\nEpoch 147/500\n242/242 [==============================] - 0s 484us/step - loss: 0.3297 - accuracy: 0.8554 - val_loss: 0.8540 - val_accuracy: 0.5574\nEpoch 148/500\n242/242 [==============================] - 0s 335us/step - loss: 0.3270 - accuracy: 0.8636 - val_loss: 0.6939 - val_accuracy: 0.6230\nEpoch 149/500\n242/242 [==============================] - 0s 318us/step - loss: 0.3225 - accuracy: 0.8554 - val_loss: 1.1729 - val_accuracy: 0.4754\nEpoch 150/500\n242/242 [==============================] - 0s 404us/step - loss: 0.3479 - accuracy: 0.8430 - val_loss: 0.7546 - val_accuracy: 0.5738\nEpoch 151/500\n242/242 [==============================] - 0s 409us/step - loss: 0.3281 - accuracy: 0.8595 - val_loss: 0.6720 - val_accuracy: 0.6230\nEpoch 152/500\n242/242 [==============================] - 0s 346us/step - loss: 0.3232 - accuracy: 0.8884 - val_loss: 1.0651 - val_accuracy: 0.5082\nEpoch 153/500\n242/242 [==============================] - 0s 435us/step - loss: 0.3223 - accuracy: 0.8471 - val_loss: 0.4892 - val_accuracy: 0.7377\nEpoch 154/500\n242/242 [==============================] - 0s 433us/step - loss: 0.3530 - accuracy: 0.8430 - val_loss: 0.7575 - val_accuracy: 0.5902\nEpoch 155/500\n242/242 [==============================] - 0s 363us/step - loss: 0.3233 - accuracy: 0.8636 - val_loss: 0.3342 - val_accuracy: 0.8361\nEpoch 156/500\n242/242 [==============================] - 0s 296us/step - loss: 0.3798 - accuracy: 0.8347 - val_loss: 0.5564 - val_accuracy: 0.6885\nEpoch 157/500\n242/242 [==============================] - 0s 533us/step - loss: 0.3480 - accuracy: 0.8471 - val_loss: 0.5643 - val_accuracy: 0.6885\nEpoch 158/500\n242/242 [==============================] - 0s 314us/step - loss: 0.3426 - accuracy: 0.8636 - val_loss: 0.7306 - val_accuracy: 0.5738\nEpoch 159/500\n242/242 [==============================] - 0s 278us/step - loss: 0.3327 - accuracy: 0.8512 - val_loss: 0.9311 - val_accuracy: 0.5574\nEpoch 160/500\n242/242 [==============================] - 0s 380us/step - loss: 0.3420 - accuracy: 0.8719 - val_loss: 0.9988 - val_accuracy: 0.5410\nEpoch 161/500\n242/242 [==============================] - 0s 499us/step - loss: 0.3527 - accuracy: 0.8512 - val_loss: 1.4506 - val_accuracy: 0.3770\nEpoch 162/500\n242/242 [==============================] - 0s 247us/step - loss: 0.3434 - accuracy: 0.8636 - val_loss: 0.9186 - val_accuracy: 0.5574\nEpoch 163/500\n242/242 [==============================] - 0s 342us/step - loss: 0.3200 - accuracy: 0.8760 - val_loss: 0.8668 - val_accuracy: 0.5574\nEpoch 164/500\n242/242 [==============================] - 0s 367us/step - loss: 0.3219 - accuracy: 0.8554 - val_loss: 0.6175 - val_accuracy: 0.6885\nEpoch 165/500\n242/242 [==============================] - 0s 362us/step - loss: 0.3358 - accuracy: 0.8719 - val_loss: 0.4725 - val_accuracy: 0.7869\nEpoch 166/500\n242/242 [==============================] - 0s 341us/step - loss: 0.3458 - accuracy: 0.8554 - val_loss: 0.5555 - val_accuracy: 0.6885\nEpoch 167/500\n242/242 [==============================] - 0s 441us/step - loss: 0.3151 - accuracy: 0.8595 - val_loss: 1.1611 - val_accuracy: 0.4754\nEpoch 168/500\n242/242 [==============================] - 0s 328us/step - loss: 0.3414 - accuracy: 0.8636 - val_loss: 0.9193 - val_accuracy: 0.5574\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 169/500\n242/242 [==============================] - 0s 412us/step - loss: 0.3326 - accuracy: 0.8512 - val_loss: 0.6595 - val_accuracy: 0.6393\nEpoch 170/500\n242/242 [==============================] - 0s 343us/step - loss: 0.3438 - accuracy: 0.8347 - val_loss: 0.7110 - val_accuracy: 0.5902\nEpoch 171/500\n242/242 [==============================] - 0s 371us/step - loss: 0.3255 - accuracy: 0.8595 - val_loss: 0.7765 - val_accuracy: 0.5574\nEpoch 172/500\n242/242 [==============================] - 0s 371us/step - loss: 0.3258 - accuracy: 0.8554 - val_loss: 0.6005 - val_accuracy: 0.6557\nEpoch 173/500\n242/242 [==============================] - 0s 549us/step - loss: 0.3366 - accuracy: 0.8554 - val_loss: 0.5242 - val_accuracy: 0.7049\nEpoch 174/500\n242/242 [==============================] - 0s 478us/step - loss: 0.3213 - accuracy: 0.8554 - val_loss: 0.6159 - val_accuracy: 0.6557\nEpoch 175/500\n242/242 [==============================] - 0s 403us/step - loss: 0.3339 - accuracy: 0.8678 - val_loss: 1.0275 - val_accuracy: 0.5246\nEpoch 176/500\n242/242 [==============================] - 0s 429us/step - loss: 0.3266 - accuracy: 0.8636 - val_loss: 0.9881 - val_accuracy: 0.5410\nEpoch 177/500\n242/242 [==============================] - 0s 323us/step - loss: 0.3252 - accuracy: 0.8636 - val_loss: 0.9809 - val_accuracy: 0.5410\nEpoch 178/500\n242/242 [==============================] - 0s 314us/step - loss: 0.3435 - accuracy: 0.8554 - val_loss: 0.9815 - val_accuracy: 0.5410\nEpoch 179/500\n242/242 [==============================] - 0s 432us/step - loss: 0.3269 - accuracy: 0.8719 - val_loss: 0.8525 - val_accuracy: 0.5574\nEpoch 180/500\n242/242 [==============================] - 0s 351us/step - loss: 0.3448 - accuracy: 0.8430 - val_loss: 0.7057 - val_accuracy: 0.5902\nEpoch 181/500\n242/242 [==============================] - 0s 284us/step - loss: 0.3254 - accuracy: 0.8554 - val_loss: 0.7230 - val_accuracy: 0.6230\nEpoch 182/500\n242/242 [==============================] - 0s 339us/step - loss: 0.3239 - accuracy: 0.8719 - val_loss: 0.7125 - val_accuracy: 0.6066\nEpoch 183/500\n242/242 [==============================] - 0s 390us/step - loss: 0.3083 - accuracy: 0.8719 - val_loss: 0.6964 - val_accuracy: 0.6230\nEpoch 184/500\n242/242 [==============================] - 0s 463us/step - loss: 0.3188 - accuracy: 0.8719 - val_loss: 0.8982 - val_accuracy: 0.5738\nEpoch 185/500\n242/242 [==============================] - 0s 354us/step - loss: 0.3326 - accuracy: 0.8843 - val_loss: 0.5689 - val_accuracy: 0.6885\nEpoch 186/500\n242/242 [==============================] - 0s 400us/step - loss: 0.3150 - accuracy: 0.8678 - val_loss: 0.8867 - val_accuracy: 0.5902\nEpoch 187/500\n242/242 [==============================] - 0s 470us/step - loss: 0.3202 - accuracy: 0.8636 - val_loss: 0.7868 - val_accuracy: 0.5902\nEpoch 188/500\n242/242 [==============================] - 0s 205us/step - loss: 0.3119 - accuracy: 0.8843 - val_loss: 0.5802 - val_accuracy: 0.6721\nEpoch 189/500\n242/242 [==============================] - 0s 344us/step - loss: 0.3406 - accuracy: 0.8430 - val_loss: 0.5331 - val_accuracy: 0.7213\nEpoch 190/500\n242/242 [==============================] - 0s 463us/step - loss: 0.3169 - accuracy: 0.8636 - val_loss: 0.6191 - val_accuracy: 0.6557\nEpoch 191/500\n242/242 [==============================] - 0s 238us/step - loss: 0.3396 - accuracy: 0.8636 - val_loss: 0.5224 - val_accuracy: 0.7377\nEpoch 192/500\n242/242 [==============================] - 0s 276us/step - loss: 0.3418 - accuracy: 0.8512 - val_loss: 0.4986 - val_accuracy: 0.7705\nEpoch 193/500\n242/242 [==============================] - 0s 246us/step - loss: 0.3270 - accuracy: 0.8636 - val_loss: 0.7153 - val_accuracy: 0.6066\nEpoch 194/500\n242/242 [==============================] - 0s 392us/step - loss: 0.3210 - accuracy: 0.8595 - val_loss: 0.9487 - val_accuracy: 0.5574\nEpoch 195/500\n242/242 [==============================] - 0s 292us/step - loss: 0.3101 - accuracy: 0.8554 - val_loss: 0.5389 - val_accuracy: 0.7049\nEpoch 196/500\n242/242 [==============================] - 0s 296us/step - loss: 0.3308 - accuracy: 0.8471 - val_loss: 0.5095 - val_accuracy: 0.7541\nEpoch 197/500\n242/242 [==============================] - 0s 329us/step - loss: 0.3647 - accuracy: 0.8430 - val_loss: 0.5753 - val_accuracy: 0.6885\nEpoch 198/500\n242/242 [==============================] - 0s 495us/step - loss: 0.3183 - accuracy: 0.8719 - val_loss: 0.7683 - val_accuracy: 0.5902\nEpoch 199/500\n242/242 [==============================] - 0s 374us/step - loss: 0.3108 - accuracy: 0.8760 - val_loss: 0.5989 - val_accuracy: 0.6557\nEpoch 200/500\n242/242 [==============================] - 0s 376us/step - loss: 0.3262 - accuracy: 0.8595 - val_loss: 0.6006 - val_accuracy: 0.6721\nEpoch 201/500\n242/242 [==============================] - 0s 357us/step - loss: 0.3125 - accuracy: 0.8719 - val_loss: 0.8354 - val_accuracy: 0.5902\nEpoch 202/500\n242/242 [==============================] - 0s 396us/step - loss: 0.3182 - accuracy: 0.8843 - val_loss: 1.1092 - val_accuracy: 0.4918\nEpoch 203/500\n242/242 [==============================] - 0s 345us/step - loss: 0.3249 - accuracy: 0.8678 - val_loss: 0.7612 - val_accuracy: 0.5902\nEpoch 204/500\n242/242 [==============================] - 0s 425us/step - loss: 0.3201 - accuracy: 0.8802 - val_loss: 0.8980 - val_accuracy: 0.5738\nEpoch 205/500\n242/242 [==============================] - 0s 529us/step - loss: 0.3071 - accuracy: 0.8760 - val_loss: 0.6426 - val_accuracy: 0.6557\nEpoch 206/500\n242/242 [==============================] - 0s 487us/step - loss: 0.3203 - accuracy: 0.8719 - val_loss: 0.7344 - val_accuracy: 0.6230\nEpoch 207/500\n242/242 [==============================] - 0s 344us/step - loss: 0.3146 - accuracy: 0.8884 - val_loss: 0.8360 - val_accuracy: 0.5738\nEpoch 208/500\n242/242 [==============================] - 0s 425us/step - loss: 0.3104 - accuracy: 0.8719 - val_loss: 0.6873 - val_accuracy: 0.6230\nEpoch 209/500\n242/242 [==============================] - 0s 423us/step - loss: 0.3080 - accuracy: 0.8760 - val_loss: 0.7526 - val_accuracy: 0.6066\nEpoch 210/500\n242/242 [==============================] - 0s 410us/step - loss: 0.3144 - accuracy: 0.8884 - val_loss: 0.8334 - val_accuracy: 0.5738\nEpoch 211/500\n242/242 [==============================] - 0s 374us/step - loss: 0.3170 - accuracy: 0.8719 - val_loss: 0.9463 - val_accuracy: 0.5082\nEpoch 212/500\n242/242 [==============================] - 0s 431us/step - loss: 0.3213 - accuracy: 0.8595 - val_loss: 0.9383 - val_accuracy: 0.5574\nEpoch 213/500\n242/242 [==============================] - 0s 296us/step - loss: 0.3379 - accuracy: 0.8388 - val_loss: 1.1839 - val_accuracy: 0.4590\nEpoch 214/500\n242/242 [==============================] - 0s 330us/step - loss: 0.3298 - accuracy: 0.8595 - val_loss: 0.8651 - val_accuracy: 0.5738\nEpoch 215/500\n242/242 [==============================] - 0s 346us/step - loss: 0.3076 - accuracy: 0.8802 - val_loss: 0.9999 - val_accuracy: 0.5246\nEpoch 216/500\n242/242 [==============================] - 0s 449us/step - loss: 0.3154 - accuracy: 0.8760 - val_loss: 1.1355 - val_accuracy: 0.4590\nEpoch 217/500\n242/242 [==============================] - 0s 343us/step - loss: 0.3394 - accuracy: 0.8554 - val_loss: 1.2988 - val_accuracy: 0.4262\nEpoch 218/500\n242/242 [==============================] - 0s 246us/step - loss: 0.3727 - accuracy: 0.8347 - val_loss: 1.4138 - val_accuracy: 0.4098\nEpoch 219/500\n242/242 [==============================] - 0s 411us/step - loss: 0.3296 - accuracy: 0.8678 - val_loss: 0.6088 - val_accuracy: 0.6721\nEpoch 220/500\n242/242 [==============================] - 0s 390us/step - loss: 0.3066 - accuracy: 0.8884 - val_loss: 0.9165 - val_accuracy: 0.5574\nEpoch 221/500\n242/242 [==============================] - 0s 338us/step - loss: 0.3377 - accuracy: 0.8512 - val_loss: 1.2133 - val_accuracy: 0.4590\nEpoch 222/500\n242/242 [==============================] - 0s 247us/step - loss: 0.3402 - accuracy: 0.8719 - val_loss: 0.8745 - val_accuracy: 0.5082\nEpoch 223/500\n242/242 [==============================] - 0s 262us/step - loss: 0.3094 - accuracy: 0.8843 - val_loss: 0.9743 - val_accuracy: 0.5410\nEpoch 224/500\n242/242 [==============================] - 0s 229us/step - loss: 0.3208 - accuracy: 0.8760 - val_loss: 1.0352 - val_accuracy: 0.4918\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 225/500\n242/242 [==============================] - 0s 524us/step - loss: 0.3147 - accuracy: 0.8636 - val_loss: 0.5828 - val_accuracy: 0.6885\nEpoch 226/500\n242/242 [==============================] - 0s 330us/step - loss: 0.3259 - accuracy: 0.8719 - val_loss: 0.5541 - val_accuracy: 0.7049\nEpoch 227/500\n242/242 [==============================] - 0s 257us/step - loss: 0.3372 - accuracy: 0.8347 - val_loss: 0.7140 - val_accuracy: 0.6066\nEpoch 228/500\n242/242 [==============================] - 0s 308us/step - loss: 0.3128 - accuracy: 0.8802 - val_loss: 0.8764 - val_accuracy: 0.5738\nEpoch 229/500\n242/242 [==============================] - 0s 464us/step - loss: 0.3100 - accuracy: 0.8884 - val_loss: 0.9218 - val_accuracy: 0.5574\nEpoch 230/500\n242/242 [==============================] - 0s 259us/step - loss: 0.3121 - accuracy: 0.8678 - val_loss: 0.9878 - val_accuracy: 0.5410\nEpoch 231/500\n242/242 [==============================] - 0s 278us/step - loss: 0.3354 - accuracy: 0.8595 - val_loss: 1.2625 - val_accuracy: 0.4262\nEpoch 232/500\n242/242 [==============================] - 0s 391us/step - loss: 0.3354 - accuracy: 0.8595 - val_loss: 1.0029 - val_accuracy: 0.4918\nEpoch 233/500\n242/242 [==============================] - 0s 398us/step - loss: 0.3493 - accuracy: 0.8512 - val_loss: 0.9073 - val_accuracy: 0.5574\nEpoch 234/500\n242/242 [==============================] - 0s 376us/step - loss: 0.3681 - accuracy: 0.8347 - val_loss: 0.7296 - val_accuracy: 0.6066\nEpoch 235/500\n242/242 [==============================] - 0s 351us/step - loss: 0.3306 - accuracy: 0.8471 - val_loss: 0.9282 - val_accuracy: 0.5410\nEpoch 236/500\n242/242 [==============================] - 0s 316us/step - loss: 0.3124 - accuracy: 0.8843 - val_loss: 0.6633 - val_accuracy: 0.6230\nEpoch 237/500\n242/242 [==============================] - 0s 360us/step - loss: 0.3067 - accuracy: 0.8802 - val_loss: 0.7442 - val_accuracy: 0.6230\nEpoch 238/500\n242/242 [==============================] - 0s 505us/step - loss: 0.3044 - accuracy: 0.8926 - val_loss: 0.9432 - val_accuracy: 0.5410\nEpoch 239/500\n242/242 [==============================] - 0s 475us/step - loss: 0.3113 - accuracy: 0.8802 - val_loss: 0.8145 - val_accuracy: 0.6066\nEpoch 240/500\n242/242 [==============================] - 0s 323us/step - loss: 0.3063 - accuracy: 0.8802 - val_loss: 1.2773 - val_accuracy: 0.4262\nEpoch 241/500\n242/242 [==============================] - 0s 317us/step - loss: 0.3395 - accuracy: 0.8636 - val_loss: 1.0018 - val_accuracy: 0.5082\nEpoch 242/500\n242/242 [==============================] - 0s 258us/step - loss: 0.3062 - accuracy: 0.8884 - val_loss: 0.9075 - val_accuracy: 0.5246\nEpoch 243/500\n242/242 [==============================] - 0s 277us/step - loss: 0.3080 - accuracy: 0.8678 - val_loss: 0.6843 - val_accuracy: 0.6557\nEpoch 244/500\n242/242 [==============================] - 0s 352us/step - loss: 0.3215 - accuracy: 0.8636 - val_loss: 1.0475 - val_accuracy: 0.5246\nEpoch 245/500\n242/242 [==============================] - 0s 311us/step - loss: 0.3049 - accuracy: 0.8636 - val_loss: 0.9633 - val_accuracy: 0.5246\nEpoch 246/500\n242/242 [==============================] - 0s 330us/step - loss: 0.3084 - accuracy: 0.8760 - val_loss: 0.5958 - val_accuracy: 0.6885\nEpoch 247/500\n242/242 [==============================] - 0s 319us/step - loss: 0.3023 - accuracy: 0.8719 - val_loss: 0.5233 - val_accuracy: 0.7049\nEpoch 248/500\n242/242 [==============================] - 0s 352us/step - loss: 0.3425 - accuracy: 0.8802 - val_loss: 1.2406 - val_accuracy: 0.4426\nEpoch 249/500\n242/242 [==============================] - 0s 447us/step - loss: 0.3084 - accuracy: 0.8802 - val_loss: 0.8642 - val_accuracy: 0.5574\nEpoch 250/500\n242/242 [==============================] - 0s 406us/step - loss: 0.3091 - accuracy: 0.8843 - val_loss: 0.6925 - val_accuracy: 0.6230\nEpoch 251/500\n242/242 [==============================] - 0s 433us/step - loss: 0.3174 - accuracy: 0.8678 - val_loss: 0.8317 - val_accuracy: 0.5902\nEpoch 252/500\n242/242 [==============================] - 0s 514us/step - loss: 0.3148 - accuracy: 0.8802 - val_loss: 0.8192 - val_accuracy: 0.5902\nEpoch 253/500\n242/242 [==============================] - 0s 471us/step - loss: 0.2983 - accuracy: 0.8760 - val_loss: 0.5831 - val_accuracy: 0.6885\nEpoch 254/500\n242/242 [==============================] - 0s 364us/step - loss: 0.3138 - accuracy: 0.8554 - val_loss: 0.4697 - val_accuracy: 0.7541\nEpoch 255/500\n242/242 [==============================] - 0s 291us/step - loss: 0.3357 - accuracy: 0.8471 - val_loss: 0.3975 - val_accuracy: 0.8033\nEpoch 256/500\n242/242 [==============================] - 0s 347us/step - loss: 0.3312 - accuracy: 0.8554 - val_loss: 0.6616 - val_accuracy: 0.6557\nEpoch 257/500\n242/242 [==============================] - 0s 271us/step - loss: 0.3103 - accuracy: 0.8760 - val_loss: 0.8005 - val_accuracy: 0.6066\nEpoch 258/500\n242/242 [==============================] - 0s 342us/step - loss: 0.3176 - accuracy: 0.8760 - val_loss: 0.4101 - val_accuracy: 0.8361\nEpoch 259/500\n242/242 [==============================] - 0s 349us/step - loss: 0.3277 - accuracy: 0.8595 - val_loss: 0.7895 - val_accuracy: 0.6066\nEpoch 260/500\n242/242 [==============================] - 0s 682us/step - loss: 0.3016 - accuracy: 0.8802 - val_loss: 1.0469 - val_accuracy: 0.5246\nEpoch 261/500\n242/242 [==============================] - 0s 454us/step - loss: 0.3043 - accuracy: 0.8802 - val_loss: 0.7727 - val_accuracy: 0.6066\nEpoch 262/500\n242/242 [==============================] - 0s 479us/step - loss: 0.3188 - accuracy: 0.8554 - val_loss: 0.5044 - val_accuracy: 0.7377\nEpoch 263/500\n242/242 [==============================] - 0s 399us/step - loss: 0.3055 - accuracy: 0.8719 - val_loss: 0.7626 - val_accuracy: 0.5902\nEpoch 264/500\n242/242 [==============================] - 0s 564us/step - loss: 0.3037 - accuracy: 0.8678 - val_loss: 1.0016 - val_accuracy: 0.5082\nEpoch 265/500\n242/242 [==============================] - 0s 446us/step - loss: 0.3029 - accuracy: 0.8843 - val_loss: 0.7939 - val_accuracy: 0.6066\nEpoch 266/500\n242/242 [==============================] - 0s 315us/step - loss: 0.3253 - accuracy: 0.8430 - val_loss: 0.9872 - val_accuracy: 0.5410\nEpoch 267/500\n242/242 [==============================] - 0s 456us/step - loss: 0.3138 - accuracy: 0.8595 - val_loss: 0.7086 - val_accuracy: 0.6230\nEpoch 268/500\n242/242 [==============================] - 0s 240us/step - loss: 0.3074 - accuracy: 0.8760 - val_loss: 0.9435 - val_accuracy: 0.5574\nEpoch 269/500\n242/242 [==============================] - 0s 309us/step - loss: 0.3152 - accuracy: 0.8595 - val_loss: 0.7436 - val_accuracy: 0.6066\nEpoch 270/500\n242/242 [==============================] - 0s 396us/step - loss: 0.3035 - accuracy: 0.8802 - val_loss: 0.8137 - val_accuracy: 0.5738\nEpoch 271/500\n242/242 [==============================] - 0s 404us/step - loss: 0.3102 - accuracy: 0.8843 - val_loss: 1.2288 - val_accuracy: 0.4426\nEpoch 272/500\n242/242 [==============================] - 0s 185us/step - loss: 0.3022 - accuracy: 0.8636 - val_loss: 0.7384 - val_accuracy: 0.6066\nEpoch 273/500\n242/242 [==============================] - 0s 320us/step - loss: 0.2983 - accuracy: 0.8926 - val_loss: 0.7192 - val_accuracy: 0.6230\nEpoch 274/500\n242/242 [==============================] - 0s 388us/step - loss: 0.3071 - accuracy: 0.8884 - val_loss: 0.6384 - val_accuracy: 0.6557\nEpoch 275/500\n242/242 [==============================] - 0s 369us/step - loss: 0.3035 - accuracy: 0.8760 - val_loss: 0.6488 - val_accuracy: 0.6557\nEpoch 276/500\n242/242 [==============================] - 0s 415us/step - loss: 0.2992 - accuracy: 0.8884 - val_loss: 1.0133 - val_accuracy: 0.4754\nEpoch 277/500\n242/242 [==============================] - 0s 356us/step - loss: 0.3098 - accuracy: 0.8802 - val_loss: 0.7230 - val_accuracy: 0.6393\nEpoch 278/500\n242/242 [==============================] - 0s 426us/step - loss: 0.3105 - accuracy: 0.8843 - val_loss: 0.8715 - val_accuracy: 0.5738\nEpoch 279/500\n242/242 [==============================] - 0s 394us/step - loss: 0.3104 - accuracy: 0.8636 - val_loss: 0.7943 - val_accuracy: 0.5902\nEpoch 280/500\n242/242 [==============================] - 0s 213us/step - loss: 0.3009 - accuracy: 0.8843 - val_loss: 0.7522 - val_accuracy: 0.6066\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 281/500\n242/242 [==============================] - 0s 242us/step - loss: 0.3095 - accuracy: 0.8595 - val_loss: 0.7566 - val_accuracy: 0.6066\nEpoch 282/500\n242/242 [==============================] - 0s 203us/step - loss: 0.3042 - accuracy: 0.8884 - val_loss: 1.0917 - val_accuracy: 0.4918\nEpoch 283/500\n242/242 [==============================] - 0s 355us/step - loss: 0.3091 - accuracy: 0.8884 - val_loss: 0.9724 - val_accuracy: 0.4918\nEpoch 284/500\n242/242 [==============================] - 0s 228us/step - loss: 0.3440 - accuracy: 0.8595 - val_loss: 1.2383 - val_accuracy: 0.4426\nEpoch 285/500\n242/242 [==============================] - 0s 336us/step - loss: 0.3117 - accuracy: 0.8678 - val_loss: 0.9440 - val_accuracy: 0.5082\nEpoch 286/500\n242/242 [==============================] - 0s 372us/step - loss: 0.3102 - accuracy: 0.8802 - val_loss: 0.8386 - val_accuracy: 0.5902\nEpoch 287/500\n242/242 [==============================] - 0s 343us/step - loss: 0.2947 - accuracy: 0.8719 - val_loss: 0.4494 - val_accuracy: 0.7705\nEpoch 288/500\n242/242 [==============================] - 0s 388us/step - loss: 0.3355 - accuracy: 0.8264 - val_loss: 0.4711 - val_accuracy: 0.7705\nEpoch 289/500\n242/242 [==============================] - 0s 303us/step - loss: 0.3392 - accuracy: 0.8471 - val_loss: 0.7445 - val_accuracy: 0.6066\nEpoch 290/500\n242/242 [==============================] - 0s 339us/step - loss: 0.2998 - accuracy: 0.8760 - val_loss: 0.9316 - val_accuracy: 0.5574\nEpoch 291/500\n242/242 [==============================] - 0s 380us/step - loss: 0.2960 - accuracy: 0.8678 - val_loss: 1.0732 - val_accuracy: 0.5246\nEpoch 292/500\n242/242 [==============================] - 0s 324us/step - loss: 0.3001 - accuracy: 0.8719 - val_loss: 0.8802 - val_accuracy: 0.5574\nEpoch 293/500\n242/242 [==============================] - 0s 398us/step - loss: 0.2974 - accuracy: 0.8802 - val_loss: 1.2981 - val_accuracy: 0.4262\nEpoch 294/500\n242/242 [==============================] - 0s 290us/step - loss: 0.3327 - accuracy: 0.8636 - val_loss: 0.9877 - val_accuracy: 0.5246\nEpoch 295/500\n242/242 [==============================] - 0s 389us/step - loss: 0.3229 - accuracy: 0.8430 - val_loss: 1.0300 - val_accuracy: 0.4918\nEpoch 296/500\n242/242 [==============================] - 0s 300us/step - loss: 0.2969 - accuracy: 0.8760 - val_loss: 0.6820 - val_accuracy: 0.6721\nEpoch 297/500\n242/242 [==============================] - 0s 207us/step - loss: 0.2980 - accuracy: 0.8843 - val_loss: 0.8248 - val_accuracy: 0.6066\nEpoch 298/500\n242/242 [==============================] - 0s 348us/step - loss: 0.2989 - accuracy: 0.8802 - val_loss: 0.9207 - val_accuracy: 0.5574\nEpoch 299/500\n242/242 [==============================] - 0s 388us/step - loss: 0.3019 - accuracy: 0.8884 - val_loss: 0.9585 - val_accuracy: 0.5410\nEpoch 300/500\n242/242 [==============================] - 0s 402us/step - loss: 0.3029 - accuracy: 0.8760 - val_loss: 0.9055 - val_accuracy: 0.5574\nEpoch 301/500\n242/242 [==============================] - 0s 348us/step - loss: 0.3046 - accuracy: 0.8636 - val_loss: 1.1400 - val_accuracy: 0.4754\nEpoch 302/500\n242/242 [==============================] - 0s 376us/step - loss: 0.3121 - accuracy: 0.8678 - val_loss: 1.0141 - val_accuracy: 0.4918\nEpoch 303/500\n242/242 [==============================] - 0s 406us/step - loss: 0.3245 - accuracy: 0.8760 - val_loss: 0.8619 - val_accuracy: 0.5902\nEpoch 304/500\n242/242 [==============================] - 0s 486us/step - loss: 0.3117 - accuracy: 0.8760 - val_loss: 0.7689 - val_accuracy: 0.5902\nEpoch 305/500\n242/242 [==============================] - 0s 335us/step - loss: 0.3038 - accuracy: 0.8636 - val_loss: 0.8404 - val_accuracy: 0.5902\nEpoch 306/500\n242/242 [==============================] - 0s 451us/step - loss: 0.2954 - accuracy: 0.8802 - val_loss: 1.0686 - val_accuracy: 0.5082\nEpoch 307/500\n242/242 [==============================] - 0s 364us/step - loss: 0.2982 - accuracy: 0.8802 - val_loss: 0.7663 - val_accuracy: 0.5902\nEpoch 308/500\n242/242 [==============================] - 0s 380us/step - loss: 0.3027 - accuracy: 0.8884 - val_loss: 0.7833 - val_accuracy: 0.5902\nEpoch 309/500\n242/242 [==============================] - 0s 414us/step - loss: 0.3109 - accuracy: 0.8636 - val_loss: 0.5427 - val_accuracy: 0.6885\nEpoch 310/500\n242/242 [==============================] - 0s 444us/step - loss: 0.3084 - accuracy: 0.8719 - val_loss: 0.7803 - val_accuracy: 0.5902\nEpoch 311/500\n242/242 [==============================] - 0s 472us/step - loss: 0.3000 - accuracy: 0.8926 - val_loss: 0.8896 - val_accuracy: 0.5738\nEpoch 312/500\n242/242 [==============================] - 0s 402us/step - loss: 0.2990 - accuracy: 0.8843 - val_loss: 1.0254 - val_accuracy: 0.5082\nEpoch 313/500\n242/242 [==============================] - 0s 432us/step - loss: 0.3197 - accuracy: 0.8678 - val_loss: 0.8249 - val_accuracy: 0.6066\nEpoch 314/500\n242/242 [==============================] - 0s 353us/step - loss: 0.3019 - accuracy: 0.8760 - val_loss: 0.5188 - val_accuracy: 0.7377\nEpoch 315/500\n242/242 [==============================] - 0s 480us/step - loss: 0.3211 - accuracy: 0.8595 - val_loss: 0.5754 - val_accuracy: 0.6885\nEpoch 316/500\n242/242 [==============================] - 0s 449us/step - loss: 0.3232 - accuracy: 0.8512 - val_loss: 0.9274 - val_accuracy: 0.5574\nEpoch 317/500\n242/242 [==============================] - 0s 412us/step - loss: 0.3026 - accuracy: 0.8802 - val_loss: 0.8762 - val_accuracy: 0.5738\nEpoch 318/500\n242/242 [==============================] - 0s 380us/step - loss: 0.3245 - accuracy: 0.8760 - val_loss: 0.7853 - val_accuracy: 0.5902\nEpoch 319/500\n242/242 [==============================] - 0s 423us/step - loss: 0.3056 - accuracy: 0.8636 - val_loss: 0.7424 - val_accuracy: 0.6066\nEpoch 320/500\n242/242 [==============================] - 0s 502us/step - loss: 0.2972 - accuracy: 0.8802 - val_loss: 0.7181 - val_accuracy: 0.6066\nEpoch 321/500\n242/242 [==============================] - 0s 459us/step - loss: 0.2978 - accuracy: 0.8802 - val_loss: 0.7246 - val_accuracy: 0.6230\nEpoch 322/500\n242/242 [==============================] - 0s 445us/step - loss: 0.2937 - accuracy: 0.8802 - val_loss: 0.6882 - val_accuracy: 0.6393\nEpoch 323/500\n242/242 [==============================] - 0s 392us/step - loss: 0.3012 - accuracy: 0.8802 - val_loss: 0.7041 - val_accuracy: 0.6066\nEpoch 324/500\n242/242 [==============================] - 0s 368us/step - loss: 0.3025 - accuracy: 0.8802 - val_loss: 0.4509 - val_accuracy: 0.7705\nEpoch 325/500\n242/242 [==============================] - 0s 417us/step - loss: 0.3156 - accuracy: 0.8719 - val_loss: 0.9027 - val_accuracy: 0.5410\nEpoch 326/500\n242/242 [==============================] - 0s 390us/step - loss: 0.3100 - accuracy: 0.8678 - val_loss: 1.0984 - val_accuracy: 0.4754\nEpoch 327/500\n242/242 [==============================] - 0s 273us/step - loss: 0.3035 - accuracy: 0.8719 - val_loss: 1.0537 - val_accuracy: 0.5082\nEpoch 328/500\n242/242 [==============================] - 0s 302us/step - loss: 0.2923 - accuracy: 0.8843 - val_loss: 0.5452 - val_accuracy: 0.6885\nEpoch 329/500\n242/242 [==============================] - 0s 329us/step - loss: 0.3146 - accuracy: 0.8554 - val_loss: 0.5476 - val_accuracy: 0.6885\nEpoch 330/500\n242/242 [==============================] - 0s 319us/step - loss: 0.3066 - accuracy: 0.8595 - val_loss: 0.6383 - val_accuracy: 0.6885\nEpoch 331/500\n242/242 [==============================] - 0s 527us/step - loss: 0.2979 - accuracy: 0.8719 - val_loss: 0.7150 - val_accuracy: 0.6393\nEpoch 332/500\n242/242 [==============================] - 0s 324us/step - loss: 0.3354 - accuracy: 0.8471 - val_loss: 0.9658 - val_accuracy: 0.5246\nEpoch 333/500\n242/242 [==============================] - 0s 398us/step - loss: 0.3200 - accuracy: 0.8719 - val_loss: 1.0686 - val_accuracy: 0.4754\nEpoch 334/500\n242/242 [==============================] - 0s 394us/step - loss: 0.3077 - accuracy: 0.8719 - val_loss: 0.8670 - val_accuracy: 0.5738\nEpoch 335/500\n242/242 [==============================] - 0s 289us/step - loss: 0.2954 - accuracy: 0.8760 - val_loss: 0.7251 - val_accuracy: 0.6230\nEpoch 336/500\n242/242 [==============================] - 0s 344us/step - loss: 0.2926 - accuracy: 0.8760 - val_loss: 1.1367 - val_accuracy: 0.4590\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 337/500\n242/242 [==============================] - 0s 347us/step - loss: 0.2975 - accuracy: 0.8719 - val_loss: 1.0159 - val_accuracy: 0.5410\nEpoch 338/500\n242/242 [==============================] - 0s 213us/step - loss: 0.3096 - accuracy: 0.8719 - val_loss: 0.8460 - val_accuracy: 0.5902\nEpoch 339/500\n242/242 [==============================] - 0s 310us/step - loss: 0.3051 - accuracy: 0.8636 - val_loss: 1.5203 - val_accuracy: 0.4098\nEpoch 340/500\n242/242 [==============================] - 0s 576us/step - loss: 0.3153 - accuracy: 0.8926 - val_loss: 0.6651 - val_accuracy: 0.6721\nEpoch 341/500\n242/242 [==============================] - 0s 330us/step - loss: 0.2971 - accuracy: 0.8719 - val_loss: 0.7964 - val_accuracy: 0.5738\nEpoch 342/500\n242/242 [==============================] - 0s 301us/step - loss: 0.3031 - accuracy: 0.8636 - val_loss: 1.0064 - val_accuracy: 0.5410\nEpoch 343/500\n242/242 [==============================] - 0s 438us/step - loss: 0.2928 - accuracy: 0.8884 - val_loss: 0.8625 - val_accuracy: 0.5902\nEpoch 344/500\n242/242 [==============================] - 0s 459us/step - loss: 0.3003 - accuracy: 0.8802 - val_loss: 0.8920 - val_accuracy: 0.5738\nEpoch 345/500\n242/242 [==============================] - 0s 572us/step - loss: 0.2936 - accuracy: 0.8884 - val_loss: 0.8561 - val_accuracy: 0.5738\nEpoch 346/500\n242/242 [==============================] - 0s 378us/step - loss: 0.2896 - accuracy: 0.8843 - val_loss: 0.7362 - val_accuracy: 0.6393\nEpoch 347/500\n242/242 [==============================] - 0s 330us/step - loss: 0.3030 - accuracy: 0.8802 - val_loss: 1.2034 - val_accuracy: 0.4590\nEpoch 348/500\n242/242 [==============================] - 0s 400us/step - loss: 0.3109 - accuracy: 0.8802 - val_loss: 0.5424 - val_accuracy: 0.6885\nEpoch 349/500\n242/242 [==============================] - 0s 402us/step - loss: 0.3117 - accuracy: 0.8760 - val_loss: 0.5240 - val_accuracy: 0.7049\nEpoch 350/500\n242/242 [==============================] - 0s 460us/step - loss: 0.3297 - accuracy: 0.8595 - val_loss: 1.0354 - val_accuracy: 0.5246\nEpoch 351/500\n242/242 [==============================] - 0s 442us/step - loss: 0.2988 - accuracy: 0.8926 - val_loss: 0.7218 - val_accuracy: 0.6066\nEpoch 352/500\n242/242 [==============================] - 0s 322us/step - loss: 0.2928 - accuracy: 0.8802 - val_loss: 0.5441 - val_accuracy: 0.6885\nEpoch 353/500\n242/242 [==============================] - 0s 450us/step - loss: 0.3496 - accuracy: 0.8388 - val_loss: 1.0605 - val_accuracy: 0.5082\nEpoch 354/500\n242/242 [==============================] - 0s 531us/step - loss: 0.3054 - accuracy: 0.8760 - val_loss: 0.9086 - val_accuracy: 0.5574\nEpoch 355/500\n242/242 [==============================] - 0s 635us/step - loss: 0.3040 - accuracy: 0.8843 - val_loss: 1.0960 - val_accuracy: 0.5082\nEpoch 356/500\n242/242 [==============================] - 0s 625us/step - loss: 0.3113 - accuracy: 0.8471 - val_loss: 1.0820 - val_accuracy: 0.4918\nEpoch 357/500\n242/242 [==============================] - 0s 501us/step - loss: 0.2854 - accuracy: 0.8843 - val_loss: 0.6350 - val_accuracy: 0.6885\nEpoch 358/500\n242/242 [==============================] - 0s 402us/step - loss: 0.3000 - accuracy: 0.8719 - val_loss: 0.8386 - val_accuracy: 0.5902\nEpoch 359/500\n242/242 [==============================] - 0s 329us/step - loss: 0.2932 - accuracy: 0.8926 - val_loss: 0.7586 - val_accuracy: 0.5902\nEpoch 360/500\n242/242 [==============================] - 0s 382us/step - loss: 0.2978 - accuracy: 0.8802 - val_loss: 1.0137 - val_accuracy: 0.5082\nEpoch 361/500\n242/242 [==============================] - 0s 410us/step - loss: 0.2999 - accuracy: 0.8843 - val_loss: 0.7842 - val_accuracy: 0.6066\nEpoch 362/500\n242/242 [==============================] - 0s 414us/step - loss: 0.2935 - accuracy: 0.8884 - val_loss: 1.0680 - val_accuracy: 0.4918\nEpoch 363/500\n242/242 [==============================] - 0s 441us/step - loss: 0.2993 - accuracy: 0.8760 - val_loss: 1.0624 - val_accuracy: 0.4918\nEpoch 364/500\n242/242 [==============================] - 0s 490us/step - loss: 0.3036 - accuracy: 0.8719 - val_loss: 0.9276 - val_accuracy: 0.5574\nEpoch 365/500\n242/242 [==============================] - 0s 215us/step - loss: 0.2893 - accuracy: 0.8884 - val_loss: 0.9767 - val_accuracy: 0.5246\nEpoch 366/500\n242/242 [==============================] - 0s 370us/step - loss: 0.2960 - accuracy: 0.8802 - val_loss: 0.8014 - val_accuracy: 0.6066\nEpoch 367/500\n242/242 [==============================] - 0s 400us/step - loss: 0.3084 - accuracy: 0.8802 - val_loss: 1.0514 - val_accuracy: 0.5410\nEpoch 368/500\n242/242 [==============================] - 0s 438us/step - loss: 0.2943 - accuracy: 0.8843 - val_loss: 1.0820 - val_accuracy: 0.4918\nEpoch 369/500\n242/242 [==============================] - 0s 554us/step - loss: 0.2989 - accuracy: 0.8802 - val_loss: 0.7191 - val_accuracy: 0.6230\nEpoch 370/500\n242/242 [==============================] - 0s 321us/step - loss: 0.2881 - accuracy: 0.8884 - val_loss: 1.2415 - val_accuracy: 0.4262\nEpoch 371/500\n242/242 [==============================] - 0s 396us/step - loss: 0.3208 - accuracy: 0.8430 - val_loss: 1.3375 - val_accuracy: 0.4426\nEpoch 372/500\n242/242 [==============================] - 0s 382us/step - loss: 0.3079 - accuracy: 0.8802 - val_loss: 0.7797 - val_accuracy: 0.5902\nEpoch 373/500\n242/242 [==============================] - 0s 418us/step - loss: 0.3019 - accuracy: 0.8595 - val_loss: 0.5481 - val_accuracy: 0.6885\nEpoch 374/500\n242/242 [==============================] - 0s 397us/step - loss: 0.3498 - accuracy: 0.8719 - val_loss: 0.6037 - val_accuracy: 0.6721\nEpoch 375/500\n242/242 [==============================] - 0s 571us/step - loss: 0.2951 - accuracy: 0.8802 - val_loss: 1.1826 - val_accuracy: 0.4590\nEpoch 376/500\n242/242 [==============================] - 0s 442us/step - loss: 0.3048 - accuracy: 0.8471 - val_loss: 1.2685 - val_accuracy: 0.4426\nEpoch 377/500\n242/242 [==============================] - 0s 416us/step - loss: 0.3649 - accuracy: 0.8306 - val_loss: 0.6998 - val_accuracy: 0.6393\nEpoch 378/500\n242/242 [==============================] - 0s 409us/step - loss: 0.3019 - accuracy: 0.8843 - val_loss: 0.6991 - val_accuracy: 0.6393\nEpoch 379/500\n242/242 [==============================] - 0s 430us/step - loss: 0.3155 - accuracy: 0.8512 - val_loss: 0.9980 - val_accuracy: 0.5410\nEpoch 380/500\n242/242 [==============================] - 0s 506us/step - loss: 0.3143 - accuracy: 0.8760 - val_loss: 0.7069 - val_accuracy: 0.6066\nEpoch 381/500\n242/242 [==============================] - 0s 461us/step - loss: 0.2887 - accuracy: 0.8926 - val_loss: 0.8303 - val_accuracy: 0.5902\nEpoch 382/500\n242/242 [==============================] - 0s 458us/step - loss: 0.3001 - accuracy: 0.8719 - val_loss: 0.7716 - val_accuracy: 0.6066\nEpoch 383/500\n242/242 [==============================] - 0s 291us/step - loss: 0.2854 - accuracy: 0.8884 - val_loss: 1.2172 - val_accuracy: 0.4590\nEpoch 384/500\n242/242 [==============================] - 0s 329us/step - loss: 0.3204 - accuracy: 0.8884 - val_loss: 0.9654 - val_accuracy: 0.5574\nEpoch 385/500\n242/242 [==============================] - 0s 299us/step - loss: 0.2994 - accuracy: 0.8843 - val_loss: 1.1173 - val_accuracy: 0.4590\nEpoch 386/500\n242/242 [==============================] - 0s 460us/step - loss: 0.2929 - accuracy: 0.8760 - val_loss: 0.7558 - val_accuracy: 0.6066\nEpoch 387/500\n242/242 [==============================] - 0s 404us/step - loss: 0.3072 - accuracy: 0.8760 - val_loss: 1.0983 - val_accuracy: 0.4918\nEpoch 388/500\n242/242 [==============================] - 0s 363us/step - loss: 0.2957 - accuracy: 0.8926 - val_loss: 1.0728 - val_accuracy: 0.4754\nEpoch 389/500\n242/242 [==============================] - 0s 472us/step - loss: 0.2957 - accuracy: 0.8843 - val_loss: 0.8943 - val_accuracy: 0.5902\nEpoch 390/500\n242/242 [==============================] - 0s 336us/step - loss: 0.2985 - accuracy: 0.8926 - val_loss: 0.8174 - val_accuracy: 0.6066\nEpoch 391/500\n242/242 [==============================] - 0s 400us/step - loss: 0.3063 - accuracy: 0.8802 - val_loss: 1.3532 - val_accuracy: 0.4262\nEpoch 392/500\n242/242 [==============================] - 0s 313us/step - loss: 0.2977 - accuracy: 0.8760 - val_loss: 0.7050 - val_accuracy: 0.6230\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 393/500\n242/242 [==============================] - 0s 264us/step - loss: 0.3194 - accuracy: 0.8760 - val_loss: 0.6561 - val_accuracy: 0.6721\nEpoch 394/500\n242/242 [==============================] - 0s 478us/step - loss: 0.3097 - accuracy: 0.8636 - val_loss: 1.1311 - val_accuracy: 0.4590\nEpoch 395/500\n242/242 [==============================] - 0s 227us/step - loss: 0.2974 - accuracy: 0.8678 - val_loss: 0.8397 - val_accuracy: 0.5902\nEpoch 396/500\n242/242 [==============================] - 0s 356us/step - loss: 0.2940 - accuracy: 0.8760 - val_loss: 0.7553 - val_accuracy: 0.6066\nEpoch 397/500\n242/242 [==============================] - 0s 437us/step - loss: 0.2917 - accuracy: 0.8802 - val_loss: 0.9401 - val_accuracy: 0.5574\nEpoch 398/500\n242/242 [==============================] - 0s 288us/step - loss: 0.3001 - accuracy: 0.8678 - val_loss: 1.1536 - val_accuracy: 0.4590\nEpoch 399/500\n242/242 [==============================] - 0s 285us/step - loss: 0.3059 - accuracy: 0.8595 - val_loss: 1.1840 - val_accuracy: 0.4754\nEpoch 400/500\n242/242 [==============================] - 0s 266us/step - loss: 0.3384 - accuracy: 0.8636 - val_loss: 1.2004 - val_accuracy: 0.4426\nEpoch 401/500\n242/242 [==============================] - 0s 300us/step - loss: 0.3019 - accuracy: 0.8636 - val_loss: 0.7668 - val_accuracy: 0.5902\nEpoch 402/500\n242/242 [==============================] - 0s 356us/step - loss: 0.2896 - accuracy: 0.8884 - val_loss: 1.0674 - val_accuracy: 0.4918\nEpoch 403/500\n242/242 [==============================] - 0s 278us/step - loss: 0.2910 - accuracy: 0.8884 - val_loss: 1.3464 - val_accuracy: 0.4426\nEpoch 404/500\n242/242 [==============================] - 0s 281us/step - loss: 0.3663 - accuracy: 0.8099 - val_loss: 1.9173 - val_accuracy: 0.3279\nEpoch 405/500\n242/242 [==============================] - 0s 278us/step - loss: 0.3597 - accuracy: 0.8595 - val_loss: 1.0227 - val_accuracy: 0.4918\nEpoch 406/500\n242/242 [==============================] - 0s 320us/step - loss: 0.3111 - accuracy: 0.8843 - val_loss: 0.8539 - val_accuracy: 0.5902\nEpoch 407/500\n242/242 [==============================] - 0s 405us/step - loss: 0.2904 - accuracy: 0.9008 - val_loss: 0.9903 - val_accuracy: 0.5410\nEpoch 408/500\n242/242 [==============================] - 0s 267us/step - loss: 0.3056 - accuracy: 0.8760 - val_loss: 1.0532 - val_accuracy: 0.4918\nEpoch 409/500\n242/242 [==============================] - 0s 407us/step - loss: 0.2937 - accuracy: 0.8884 - val_loss: 1.2870 - val_accuracy: 0.4426\nEpoch 410/500\n242/242 [==============================] - 0s 370us/step - loss: 0.2971 - accuracy: 0.8843 - val_loss: 1.1678 - val_accuracy: 0.4590\nEpoch 411/500\n242/242 [==============================] - 0s 271us/step - loss: 0.2978 - accuracy: 0.8719 - val_loss: 0.9620 - val_accuracy: 0.5574\nEpoch 412/500\n242/242 [==============================] - 0s 270us/step - loss: 0.2904 - accuracy: 0.8843 - val_loss: 1.0475 - val_accuracy: 0.4918\nEpoch 413/500\n242/242 [==============================] - 0s 281us/step - loss: 0.3284 - accuracy: 0.8595 - val_loss: 0.8008 - val_accuracy: 0.6066\nEpoch 414/500\n242/242 [==============================] - 0s 594us/step - loss: 0.2972 - accuracy: 0.8967 - val_loss: 0.7541 - val_accuracy: 0.6230\nEpoch 415/500\n242/242 [==============================] - 0s 432us/step - loss: 0.2849 - accuracy: 0.8967 - val_loss: 1.0584 - val_accuracy: 0.5246\nEpoch 416/500\n242/242 [==============================] - 0s 378us/step - loss: 0.2918 - accuracy: 0.8802 - val_loss: 0.8783 - val_accuracy: 0.5902\nEpoch 417/500\n242/242 [==============================] - 0s 477us/step - loss: 0.3024 - accuracy: 0.8802 - val_loss: 0.5546 - val_accuracy: 0.6885\nEpoch 418/500\n242/242 [==============================] - 0s 358us/step - loss: 0.3062 - accuracy: 0.8926 - val_loss: 0.8628 - val_accuracy: 0.5738\nEpoch 419/500\n242/242 [==============================] - 0s 355us/step - loss: 0.2945 - accuracy: 0.8843 - val_loss: 0.7586 - val_accuracy: 0.6230\nEpoch 420/500\n242/242 [==============================] - 0s 319us/step - loss: 0.3090 - accuracy: 0.8802 - val_loss: 1.0911 - val_accuracy: 0.4590\nEpoch 421/500\n242/242 [==============================] - 0s 254us/step - loss: 0.2843 - accuracy: 0.8760 - val_loss: 0.5319 - val_accuracy: 0.6885\nEpoch 422/500\n242/242 [==============================] - 0s 358us/step - loss: 0.3113 - accuracy: 0.8802 - val_loss: 0.6995 - val_accuracy: 0.6393\nEpoch 423/500\n242/242 [==============================] - 0s 463us/step - loss: 0.2889 - accuracy: 0.8843 - val_loss: 1.0549 - val_accuracy: 0.4918\nEpoch 424/500\n242/242 [==============================] - 0s 274us/step - loss: 0.2940 - accuracy: 0.8719 - val_loss: 1.3920 - val_accuracy: 0.4262\nEpoch 425/500\n242/242 [==============================] - 0s 379us/step - loss: 0.3014 - accuracy: 0.8926 - val_loss: 0.9014 - val_accuracy: 0.5574\nEpoch 426/500\n242/242 [==============================] - 0s 331us/step - loss: 0.2836 - accuracy: 0.8843 - val_loss: 0.5475 - val_accuracy: 0.6885\nEpoch 427/500\n242/242 [==============================] - 0s 374us/step - loss: 0.3016 - accuracy: 0.8802 - val_loss: 0.6650 - val_accuracy: 0.6557\nEpoch 428/500\n242/242 [==============================] - 0s 353us/step - loss: 0.2913 - accuracy: 0.8926 - val_loss: 0.8699 - val_accuracy: 0.5738\nEpoch 429/500\n242/242 [==============================] - 0s 401us/step - loss: 0.2865 - accuracy: 0.8802 - val_loss: 0.6968 - val_accuracy: 0.6393\nEpoch 430/500\n242/242 [==============================] - 0s 470us/step - loss: 0.3065 - accuracy: 0.8595 - val_loss: 0.7802 - val_accuracy: 0.6066\nEpoch 431/500\n242/242 [==============================] - 0s 453us/step - loss: 0.3317 - accuracy: 0.8678 - val_loss: 1.0445 - val_accuracy: 0.5082\nEpoch 432/500\n242/242 [==============================] - 0s 337us/step - loss: 0.2830 - accuracy: 0.9050 - val_loss: 0.9211 - val_accuracy: 0.5738\nEpoch 433/500\n242/242 [==============================] - 0s 318us/step - loss: 0.2975 - accuracy: 0.8802 - val_loss: 0.9311 - val_accuracy: 0.5738\nEpoch 434/500\n242/242 [==============================] - 0s 578us/step - loss: 0.2980 - accuracy: 0.8843 - val_loss: 0.9060 - val_accuracy: 0.5574\nEpoch 435/500\n242/242 [==============================] - 0s 401us/step - loss: 0.2954 - accuracy: 0.8719 - val_loss: 1.0265 - val_accuracy: 0.5410\nEpoch 436/500\n242/242 [==============================] - 0s 410us/step - loss: 0.2902 - accuracy: 0.8719 - val_loss: 0.9019 - val_accuracy: 0.5738\nEpoch 437/500\n242/242 [==============================] - 0s 321us/step - loss: 0.3210 - accuracy: 0.8471 - val_loss: 0.8384 - val_accuracy: 0.5574\nEpoch 438/500\n242/242 [==============================] - 0s 377us/step - loss: 0.3132 - accuracy: 0.8719 - val_loss: 0.5975 - val_accuracy: 0.6885\nEpoch 439/500\n242/242 [==============================] - 0s 395us/step - loss: 0.2871 - accuracy: 0.8760 - val_loss: 0.6917 - val_accuracy: 0.6393\nEpoch 440/500\n242/242 [==============================] - 0s 366us/step - loss: 0.2889 - accuracy: 0.8843 - val_loss: 1.0580 - val_accuracy: 0.5082\nEpoch 441/500\n242/242 [==============================] - 0s 341us/step - loss: 0.2830 - accuracy: 0.8843 - val_loss: 0.7036 - val_accuracy: 0.6393\nEpoch 442/500\n242/242 [==============================] - 0s 389us/step - loss: 0.2937 - accuracy: 0.8843 - val_loss: 0.8618 - val_accuracy: 0.5738\nEpoch 443/500\n242/242 [==============================] - 0s 404us/step - loss: 0.2834 - accuracy: 0.8843 - val_loss: 0.5721 - val_accuracy: 0.6885\nEpoch 444/500\n242/242 [==============================] - 0s 457us/step - loss: 0.3020 - accuracy: 0.8719 - val_loss: 0.7886 - val_accuracy: 0.5902\nEpoch 445/500\n242/242 [==============================] - 0s 330us/step - loss: 0.2866 - accuracy: 0.8802 - val_loss: 0.7644 - val_accuracy: 0.6066\nEpoch 446/500\n242/242 [==============================] - 0s 441us/step - loss: 0.2930 - accuracy: 0.8802 - val_loss: 0.7900 - val_accuracy: 0.6066\nEpoch 447/500\n242/242 [==============================] - 0s 317us/step - loss: 0.2834 - accuracy: 0.8967 - val_loss: 1.1417 - val_accuracy: 0.4754\nEpoch 448/500\n242/242 [==============================] - 0s 395us/step - loss: 0.2878 - accuracy: 0.8760 - val_loss: 0.7312 - val_accuracy: 0.6066\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 449/500\n242/242 [==============================] - 0s 432us/step - loss: 0.2841 - accuracy: 0.8843 - val_loss: 0.8990 - val_accuracy: 0.5902\nEpoch 450/500\n242/242 [==============================] - 0s 331us/step - loss: 0.3032 - accuracy: 0.8802 - val_loss: 0.9620 - val_accuracy: 0.5738\nEpoch 451/500\n242/242 [==============================] - 0s 269us/step - loss: 0.2895 - accuracy: 0.8760 - val_loss: 0.8555 - val_accuracy: 0.5738\nEpoch 452/500\n242/242 [==============================] - 0s 310us/step - loss: 0.3190 - accuracy: 0.8636 - val_loss: 1.1039 - val_accuracy: 0.4918\nEpoch 453/500\n242/242 [==============================] - 0s 317us/step - loss: 0.2938 - accuracy: 0.8967 - val_loss: 1.4823 - val_accuracy: 0.3934\nEpoch 454/500\n242/242 [==============================] - 0s 470us/step - loss: 0.3120 - accuracy: 0.8802 - val_loss: 0.7534 - val_accuracy: 0.6066\nEpoch 455/500\n242/242 [==============================] - 0s 363us/step - loss: 0.2850 - accuracy: 0.8760 - val_loss: 0.8257 - val_accuracy: 0.6066\nEpoch 456/500\n242/242 [==============================] - 0s 344us/step - loss: 0.2763 - accuracy: 0.8719 - val_loss: 1.4888 - val_accuracy: 0.3934\nEpoch 457/500\n242/242 [==============================] - 0s 334us/step - loss: 0.3013 - accuracy: 0.8967 - val_loss: 1.0271 - val_accuracy: 0.5410\nEpoch 458/500\n242/242 [==============================] - 0s 245us/step - loss: 0.2819 - accuracy: 0.8967 - val_loss: 0.8321 - val_accuracy: 0.5902\nEpoch 459/500\n242/242 [==============================] - 0s 259us/step - loss: 0.2829 - accuracy: 0.8926 - val_loss: 0.6960 - val_accuracy: 0.6393\nEpoch 460/500\n242/242 [==============================] - 0s 278us/step - loss: 0.2952 - accuracy: 0.8843 - val_loss: 0.8485 - val_accuracy: 0.5738\nEpoch 461/500\n242/242 [==============================] - 0s 276us/step - loss: 0.2892 - accuracy: 0.8843 - val_loss: 0.9735 - val_accuracy: 0.5738\nEpoch 462/500\n242/242 [==============================] - 0s 361us/step - loss: 0.3084 - accuracy: 0.8636 - val_loss: 0.6529 - val_accuracy: 0.6557\nEpoch 463/500\n242/242 [==============================] - 0s 338us/step - loss: 0.3008 - accuracy: 0.8802 - val_loss: 0.8330 - val_accuracy: 0.5902\nEpoch 464/500\n242/242 [==============================] - 0s 393us/step - loss: 0.2943 - accuracy: 0.8802 - val_loss: 0.6344 - val_accuracy: 0.6721\nEpoch 465/500\n242/242 [==============================] - 0s 234us/step - loss: 0.2976 - accuracy: 0.8802 - val_loss: 1.0128 - val_accuracy: 0.5410\nEpoch 466/500\n242/242 [==============================] - 0s 295us/step - loss: 0.2917 - accuracy: 0.8926 - val_loss: 0.7888 - val_accuracy: 0.6066\nEpoch 467/500\n242/242 [==============================] - 0s 282us/step - loss: 0.2881 - accuracy: 0.8926 - val_loss: 0.7330 - val_accuracy: 0.6230\nEpoch 468/500\n242/242 [==============================] - 0s 376us/step - loss: 0.2896 - accuracy: 0.8967 - val_loss: 1.0681 - val_accuracy: 0.4918\nEpoch 469/500\n242/242 [==============================] - 0s 387us/step - loss: 0.2967 - accuracy: 0.8802 - val_loss: 0.6789 - val_accuracy: 0.6557\nEpoch 470/500\n242/242 [==============================] - 0s 390us/step - loss: 0.2989 - accuracy: 0.8967 - val_loss: 1.0252 - val_accuracy: 0.5246\nEpoch 471/500\n242/242 [==============================] - 0s 382us/step - loss: 0.2802 - accuracy: 0.9008 - val_loss: 0.6568 - val_accuracy: 0.6557\nEpoch 472/500\n242/242 [==============================] - 0s 263us/step - loss: 0.2978 - accuracy: 0.8843 - val_loss: 0.5804 - val_accuracy: 0.6721\nEpoch 473/500\n242/242 [==============================] - 0s 325us/step - loss: 0.2927 - accuracy: 0.8802 - val_loss: 0.8697 - val_accuracy: 0.5902\nEpoch 474/500\n242/242 [==============================] - 0s 322us/step - loss: 0.2850 - accuracy: 0.8926 - val_loss: 0.9517 - val_accuracy: 0.5738\nEpoch 475/500\n242/242 [==============================] - 0s 367us/step - loss: 0.2804 - accuracy: 0.8926 - val_loss: 1.0467 - val_accuracy: 0.5246\nEpoch 476/500\n242/242 [==============================] - 0s 280us/step - loss: 0.3013 - accuracy: 0.8719 - val_loss: 0.5796 - val_accuracy: 0.6885\nEpoch 477/500\n242/242 [==============================] - 0s 411us/step - loss: 0.2896 - accuracy: 0.8719 - val_loss: 0.9770 - val_accuracy: 0.5574\nEpoch 478/500\n242/242 [==============================] - 0s 565us/step - loss: 0.2922 - accuracy: 0.8802 - val_loss: 0.7222 - val_accuracy: 0.6230\nEpoch 479/500\n242/242 [==============================] - 0s 410us/step - loss: 0.3050 - accuracy: 0.8678 - val_loss: 0.6956 - val_accuracy: 0.6393\nEpoch 480/500\n242/242 [==============================] - 0s 486us/step - loss: 0.2821 - accuracy: 0.8802 - val_loss: 1.2531 - val_accuracy: 0.4590\nEpoch 481/500\n242/242 [==============================] - 0s 423us/step - loss: 0.3201 - accuracy: 0.8760 - val_loss: 1.1004 - val_accuracy: 0.5082\nEpoch 482/500\n242/242 [==============================] - 0s 437us/step - loss: 0.3231 - accuracy: 0.8430 - val_loss: 1.3402 - val_accuracy: 0.4262\nEpoch 483/500\n242/242 [==============================] - 0s 371us/step - loss: 0.2796 - accuracy: 0.8843 - val_loss: 0.7328 - val_accuracy: 0.6230\nEpoch 484/500\n242/242 [==============================] - 0s 353us/step - loss: 0.2823 - accuracy: 0.8760 - val_loss: 0.5157 - val_accuracy: 0.7213\nEpoch 485/500\n242/242 [==============================] - 0s 254us/step - loss: 0.3370 - accuracy: 0.8471 - val_loss: 0.6097 - val_accuracy: 0.6721\nEpoch 486/500\n242/242 [==============================] - 0s 422us/step - loss: 0.3154 - accuracy: 0.8719 - val_loss: 0.4782 - val_accuracy: 0.7541\nEpoch 487/500\n242/242 [==============================] - 0s 262us/step - loss: 0.3075 - accuracy: 0.8512 - val_loss: 1.0889 - val_accuracy: 0.4754\nEpoch 488/500\n242/242 [==============================] - 0s 285us/step - loss: 0.2896 - accuracy: 0.8926 - val_loss: 1.0803 - val_accuracy: 0.5082\nEpoch 489/500\n242/242 [==============================] - 0s 415us/step - loss: 0.3046 - accuracy: 0.8760 - val_loss: 0.6047 - val_accuracy: 0.6885\nEpoch 490/500\n242/242 [==============================] - 0s 323us/step - loss: 0.2869 - accuracy: 0.8884 - val_loss: 0.6759 - val_accuracy: 0.6393\nEpoch 491/500\n242/242 [==============================] - 0s 386us/step - loss: 0.2856 - accuracy: 0.8719 - val_loss: 1.0158 - val_accuracy: 0.5410\nEpoch 492/500\n242/242 [==============================] - 0s 322us/step - loss: 0.2777 - accuracy: 0.8843 - val_loss: 0.9368 - val_accuracy: 0.5738\nEpoch 493/500\n242/242 [==============================] - 0s 449us/step - loss: 0.3046 - accuracy: 0.8802 - val_loss: 0.6428 - val_accuracy: 0.6721\nEpoch 494/500\n242/242 [==============================] - 0s 451us/step - loss: 0.2972 - accuracy: 0.8802 - val_loss: 0.5482 - val_accuracy: 0.7049\nEpoch 495/500\n242/242 [==============================] - 0s 453us/step - loss: 0.3156 - accuracy: 0.8760 - val_loss: 0.4838 - val_accuracy: 0.7541\nEpoch 496/500\n242/242 [==============================] - 0s 320us/step - loss: 0.3005 - accuracy: 0.8843 - val_loss: 0.4968 - val_accuracy: 0.7377\nEpoch 497/500\n242/242 [==============================] - 0s 428us/step - loss: 0.3093 - accuracy: 0.8595 - val_loss: 0.8602 - val_accuracy: 0.6066\nEpoch 498/500\n242/242 [==============================] - 0s 306us/step - loss: 0.3065 - accuracy: 0.8802 - val_loss: 0.7352 - val_accuracy: 0.6066\nEpoch 499/500\n242/242 [==============================] - 0s 430us/step - loss: 0.2835 - accuracy: 0.9008 - val_loss: 1.0408 - val_accuracy: 0.5082\nEpoch 500/500\n242/242 [==============================] - 0s 399us/step - loss: 0.2835 - accuracy: 0.8884 - val_loss: 0.7677 - val_accuracy: 0.6066\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "<keras.callbacks.callbacks.History at 0x7f5a9b93ab38>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']))",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "None\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "scoresss = model.evaluate(X, Y)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "303/303 [==============================] - 0s 101us/step\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\nPresnosť siete: %.2f%%\" % (scoresss[1]*100))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\nPresnosť siete: 83.50%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y_pred_nn = model.predict(X)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y_pred_nn.shape",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "(303, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\n\nprint(\"Accuracy:\",metrics.accuracy_score(Y_pred_nn, Y))",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ad5c40d29ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}